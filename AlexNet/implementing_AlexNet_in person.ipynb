{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548daa27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a351194",
   "metadata": {},
   "source": [
    "## AlexNet 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fec9ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module) : \n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.conv1=nn.Sequential(\n",
    "                nn.Conv2d(3,96,kernel_size=(4,4)),\n",
    "                nn.ReLU(inplace = True)\n",
    "        )\n",
    "        \n",
    "        self.conv2=nn.Sequential(\n",
    "                nn.Conv2d(96,256,kernel_size=(5,5),padding=(2,2)),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv3=nn.Sequential(\n",
    "                nn.Conv2d(256,384,kernel_size=(3,3),padding=(1,1)),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(384,384,kernel_size=(3,3),padding=(1,1)),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(384,256,kernel_size=(3,3),padding=(1,1)),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        )\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.conv1(x)\n",
    "        out=self.conv2(out)\n",
    "        out=self.conv3(out)\n",
    "        out = out.view(-1,9216)\n",
    "        out=self.fc_layer1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda5f62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layer1): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4c6267",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c4d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0007e23",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 29, 29]           4,704\n",
      "              ReLU-2           [-1, 96, 29, 29]               0\n",
      "            Conv2d-3          [-1, 256, 29, 29]         614,656\n",
      "              ReLU-4          [-1, 256, 29, 29]               0\n",
      "         MaxPool2d-5          [-1, 256, 14, 14]               0\n",
      "            Conv2d-6          [-1, 384, 14, 14]         885,120\n",
      "              ReLU-7          [-1, 384, 14, 14]               0\n",
      "            Conv2d-8          [-1, 384, 14, 14]       1,327,488\n",
      "              ReLU-9          [-1, 384, 14, 14]               0\n",
      "           Conv2d-10          [-1, 256, 14, 14]         884,992\n",
      "             ReLU-11          [-1, 256, 14, 14]               0\n",
      "        MaxPool2d-12            [-1, 256, 6, 6]               0\n",
      "          Dropout-13                 [-1, 9216]               0\n",
      "           Linear-14                 [-1, 4096]      37,752,832\n",
      "             ReLU-15                 [-1, 4096]               0\n",
      "          Dropout-16                 [-1, 4096]               0\n",
      "           Linear-17                 [-1, 4096]      16,781,312\n",
      "             ReLU-18                 [-1, 4096]               0\n",
      "           Linear-19                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 58,292,074\n",
      "Trainable params: 58,292,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 8.26\n",
      "Params size (MB): 222.37\n",
      "Estimated Total Size (MB): 230.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,(3,32,32),device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e80c61",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리(이미지를 탠서화,일반화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0535226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "transformation = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
    "## 이미지 전처리인 탠서화와 일반화를 Compose로 묶어놓음\n",
    "\n",
    "train_loader = torchvision.datasets.CIFAR10(root=\"./\", transform=transformation,train=True)\n",
    "test_loader = torchvision.datasets.CIFAR10(root=\"./\",transform=transformation,train=False)\n",
    "## cifar10의 이미지를 전부 다 전처리해서 train_loader와 test_loader에 저장\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5790082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torchvision.datasets in torchvision:\n",
      "\n",
      "NAME\n",
      "    torchvision.datasets\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _optical_flow\n",
      "    _stereo_matching\n",
      "    caltech\n",
      "    celeba\n",
      "    cifar\n",
      "    cityscapes\n",
      "    clevr\n",
      "    coco\n",
      "    country211\n",
      "    dtd\n",
      "    eurosat\n",
      "    fakedata\n",
      "    fer2013\n",
      "    fgvc_aircraft\n",
      "    flickr\n",
      "    flowers102\n",
      "    folder\n",
      "    food101\n",
      "    gtsrb\n",
      "    hmdb51\n",
      "    imagenet\n",
      "    inaturalist\n",
      "    kinetics\n",
      "    kitti\n",
      "    lfw\n",
      "    lsun\n",
      "    mnist\n",
      "    omniglot\n",
      "    oxford_iiit_pet\n",
      "    pcam\n",
      "    phototour\n",
      "    places365\n",
      "    rendered_sst2\n",
      "    samplers (package)\n",
      "    sbd\n",
      "    sbu\n",
      "    semeion\n",
      "    stanford_cars\n",
      "    stl10\n",
      "    sun397\n",
      "    svhn\n",
      "    ucf101\n",
      "    usps\n",
      "    utils\n",
      "    video_utils\n",
      "    vision\n",
      "    voc\n",
      "    widerface\n",
      "\n",
      "CLASSES\n",
      "    torch.utils.data.dataset.Dataset(typing.Generic)\n",
      "        torchvision.datasets.vision.VisionDataset\n",
      "            torchvision.datasets.caltech.Caltech101\n",
      "            torchvision.datasets.caltech.Caltech256\n",
      "            torchvision.datasets.celeba.CelebA\n",
      "            torchvision.datasets.cifar.CIFAR10\n",
      "                torchvision.datasets.cifar.CIFAR100\n",
      "            torchvision.datasets.cityscapes.Cityscapes\n",
      "            torchvision.datasets.clevr.CLEVRClassification\n",
      "            torchvision.datasets.coco.CocoDetection\n",
      "                torchvision.datasets.coco.CocoCaptions\n",
      "            torchvision.datasets.dtd.DTD\n",
      "            torchvision.datasets.fakedata.FakeData\n",
      "            torchvision.datasets.fer2013.FER2013\n",
      "            torchvision.datasets.fgvc_aircraft.FGVCAircraft\n",
      "            torchvision.datasets.flickr.Flickr30k\n",
      "            torchvision.datasets.flickr.Flickr8k\n",
      "            torchvision.datasets.flowers102.Flowers102\n",
      "            torchvision.datasets.folder.DatasetFolder\n",
      "                torchvision.datasets.folder.ImageFolder\n",
      "                    torchvision.datasets.country211.Country211\n",
      "                    torchvision.datasets.eurosat.EuroSAT\n",
      "                    torchvision.datasets.imagenet.ImageNet\n",
      "            torchvision.datasets.food101.Food101\n",
      "            torchvision.datasets.gtsrb.GTSRB\n",
      "            torchvision.datasets.hmdb51.HMDB51\n",
      "            torchvision.datasets.inaturalist.INaturalist\n",
      "            torchvision.datasets.kinetics.Kinetics\n",
      "            torchvision.datasets.kitti.Kitti\n",
      "            torchvision.datasets.lsun.LSUN\n",
      "            torchvision.datasets.lsun.LSUNClass\n",
      "            torchvision.datasets.mnist.MNIST\n",
      "                torchvision.datasets.mnist.EMNIST\n",
      "                torchvision.datasets.mnist.FashionMNIST\n",
      "                torchvision.datasets.mnist.KMNIST\n",
      "                torchvision.datasets.mnist.QMNIST\n",
      "            torchvision.datasets.omniglot.Omniglot\n",
      "            torchvision.datasets.oxford_iiit_pet.OxfordIIITPet\n",
      "            torchvision.datasets.pcam.PCAM\n",
      "            torchvision.datasets.phototour.PhotoTour\n",
      "            torchvision.datasets.places365.Places365\n",
      "            torchvision.datasets.rendered_sst2.RenderedSST2\n",
      "            torchvision.datasets.sbd.SBDataset\n",
      "            torchvision.datasets.sbu.SBU\n",
      "            torchvision.datasets.semeion.SEMEION\n",
      "            torchvision.datasets.stanford_cars.StanfordCars\n",
      "            torchvision.datasets.stl10.STL10\n",
      "            torchvision.datasets.sun397.SUN397\n",
      "            torchvision.datasets.svhn.SVHN\n",
      "            torchvision.datasets.ucf101.UCF101\n",
      "            torchvision.datasets.usps.USPS\n",
      "            torchvision.datasets.widerface.WIDERFace\n",
      "    torchvision.datasets._optical_flow.FlowDataset(abc.ABC, torchvision.datasets.vision.VisionDataset)\n",
      "        torchvision.datasets._optical_flow.FlyingChairs\n",
      "        torchvision.datasets._optical_flow.FlyingThings3D\n",
      "        torchvision.datasets._optical_flow.HD1K\n",
      "        torchvision.datasets._optical_flow.KittiFlow\n",
      "        torchvision.datasets._optical_flow.Sintel\n",
      "    torchvision.datasets._stereo_matching.StereoMatchingDataset(abc.ABC, torchvision.datasets.vision.VisionDataset)\n",
      "        torchvision.datasets._stereo_matching.CREStereo\n",
      "        torchvision.datasets._stereo_matching.CarlaStereo\n",
      "        torchvision.datasets._stereo_matching.ETH3DStereo\n",
      "        torchvision.datasets._stereo_matching.FallingThingsStereo\n",
      "        torchvision.datasets._stereo_matching.InStereo2k\n",
      "        torchvision.datasets._stereo_matching.Kitti2012Stereo\n",
      "        torchvision.datasets._stereo_matching.Kitti2015Stereo\n",
      "        torchvision.datasets._stereo_matching.Middlebury2014Stereo\n",
      "        torchvision.datasets._stereo_matching.SceneFlowStereo\n",
      "        torchvision.datasets._stereo_matching.SintelStereo\n",
      "    torchvision.datasets.lfw._LFW(torchvision.datasets.vision.VisionDataset)\n",
      "        torchvision.datasets.lfw.LFWPairs\n",
      "        torchvision.datasets.lfw.LFWPeople\n",
      "    torchvision.datasets.voc._VOCBase(torchvision.datasets.vision.VisionDataset)\n",
      "        torchvision.datasets.voc.VOCDetection\n",
      "        torchvision.datasets.voc.VOCSegmentation\n",
      "    \n",
      "    class CIFAR10(torchvision.datasets.vision.VisionDataset)\n",
      "     |  CIFAR10(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
      "     |      train (bool, optional): If True, creates dataset from training set, otherwise\n",
      "     |          creates from test set.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CIFAR10\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  base_folder = 'cifar-10-batches-py'\n",
      "     |  \n",
      "     |  filename = 'cifar-10-python.tar.gz'\n",
      "     |  \n",
      "     |  meta = {'filename': 'batches.meta', 'key': 'label_names', 'md5': '5ff9...\n",
      "     |  \n",
      "     |  test_list = [['test_batch', '40351d587109b95175f43aff81a1287e']]\n",
      "     |  \n",
      "     |  tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
      "     |  \n",
      "     |  train_list = [['data_batch_1', 'c99cafc152244af753f735de768cd75f'], ['...\n",
      "     |  \n",
      "     |  url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class CIFAR100(CIFAR10)\n",
      "     |  CIFAR100(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
      "     |  \n",
      "     |  This is a subclass of the `CIFAR10` Dataset.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CIFAR100\n",
      "     |      CIFAR10\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  base_folder = 'cifar-100-python'\n",
      "     |  \n",
      "     |  filename = 'cifar-100-python.tar.gz'\n",
      "     |  \n",
      "     |  meta = {'filename': 'meta', 'key': 'fine_label_names', 'md5': '7973b15...\n",
      "     |  \n",
      "     |  test_list = [['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc']]\n",
      "     |  \n",
      "     |  tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
      "     |  \n",
      "     |  train_list = [['train', '16019d7e3df5f24257cddd939b257f8d']]\n",
      "     |  \n",
      "     |  url = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CIFAR10:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class CLEVRClassification(torchvision.datasets.vision.VisionDataset)\n",
      "     |  CLEVRClassification(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `CLEVR <https://cs.stanford.edu/people/jcjohns/clevr/>`_  classification dataset.\n",
      "     |  \n",
      "     |  The number of objects in a scene are used as label.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory ``root/clevr`` exists or will be saved to if download is\n",
      "     |          set to True.\n",
      "     |      split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"val\"``, or ``\"test\"``.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in them target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and puts it in root directory. If\n",
      "     |          dataset is already downloaded, it is not downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CLEVRClassification\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class CREStereo(StereoMatchingDataset)\n",
      "     |  CREStereo(root: str, transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  Synthetic dataset used in training the `CREStereo <https://arxiv.org/pdf/2203.11483.pdf>`_ architecture.\n",
      "     |  Dataset details on the official paper `repo <https://github.com/megvii-research/CREStereo>`_.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          CREStereo\n",
      "     |              tree\n",
      "     |                  img1_left.jpg\n",
      "     |                  img1_right.jpg\n",
      "     |                  img1_left.disp.jpg\n",
      "     |                  img1_right.disp.jpg\n",
      "     |                  img2_left.jpg\n",
      "     |                  img2_right.jpg\n",
      "     |                  img2_left.disp.jpg\n",
      "     |                  img2_right.disp.jpg\n",
      "     |                  ...\n",
      "     |              shapenet\n",
      "     |                  img1_left.jpg\n",
      "     |                  img1_right.jpg\n",
      "     |                  img1_left.disp.jpg\n",
      "     |                  img1_right.disp.jpg\n",
      "     |                  ...\n",
      "     |              reflective\n",
      "     |                  img1_left.jpg\n",
      "     |                  img1_right.jpg\n",
      "     |                  img1_left.disp.jpg\n",
      "     |                  img1_right.disp.jpg\n",
      "     |                  ...\n",
      "     |              hole\n",
      "     |                  img1_left.jpg\n",
      "     |                  img1_right.jpg\n",
      "     |                  img1_left.disp.jpg\n",
      "     |                  img1_right.disp.jpg\n",
      "     |                  ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (str): Root directory of the dataset.\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CREStereo\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 4-tuple with ``(img_left, img_right, disparity, valid_mask)``.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images.\n",
      "     |          ``valid_mask`` is implicitly ``None`` if the ``transforms`` parameter does not\n",
      "     |          generate a valid mask.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transforms: Optional[Callable] = None)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Caltech101(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Caltech101(root: str, target_type: Union[List[str], str] = 'category', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Caltech 101 <https://data.caltech.edu/records/20086>`_ Dataset.\n",
      "     |  \n",
      "     |  .. warning::\n",
      "     |  \n",
      "     |      This class needs `scipy <https://docs.scipy.org/doc/>`_ to load target files from `.mat` format.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``caltech101`` exists or will be saved to if download is set to True.\n",
      "     |      target_type (string or list, optional): Type of target to use, ``category`` or\n",
      "     |          ``annotation``. Can also be a list to output a tuple with all specified\n",
      "     |          target types.  ``category`` represents the target class, and\n",
      "     |          ``annotation`` is a list of points from a hand-generated outline.\n",
      "     |          Defaults to ``category``.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Caltech101\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where the type of target specified by target_type.\n",
      "     |  \n",
      "     |  __init__(self, root: str, target_type: Union[List[str], str] = 'category', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Caltech256(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Caltech256(root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Caltech 256 <https://data.caltech.edu/records/20087>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``caltech256`` exists or will be saved to if download is set to True.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Caltech256\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class CarlaStereo(StereoMatchingDataset)\n",
      "     |  CarlaStereo(root: str, transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  Carla simulator data linked in the `CREStereo github repo <https://github.com/megvii-research/CREStereo>`_.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          carla-highres\n",
      "     |              trainingF\n",
      "     |                  scene1\n",
      "     |                      img0.png\n",
      "     |                      img1.png\n",
      "     |                      disp0GT.pfm\n",
      "     |                      disp1GT.pfm\n",
      "     |                      calib.txt\n",
      "     |                  scene2\n",
      "     |                      img0.png\n",
      "     |                      img1.png\n",
      "     |                      disp0GT.pfm\n",
      "     |                      disp1GT.pfm\n",
      "     |                      calib.txt\n",
      "     |                  ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where `carla-highres` is located.\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CarlaStereo\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 3-tuple with ``(img_left, img_right, disparity)``.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images.\n",
      "     |          If a ``valid_mask`` is generated within the ``transforms`` parameter,\n",
      "     |          a 4-tuple with ``(img_left, img_right, disparity, valid_mask)`` is returned.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transforms: Optional[Callable] = None)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class CelebA(torchvision.datasets.vision.VisionDataset)\n",
      "     |  CelebA(root: str, split: str = 'train', target_type: Union[List[str], str] = 'attr', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Large-scale CelebFaces Attributes (CelebA) Dataset <http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      split (string): One of {'train', 'valid', 'test', 'all'}.\n",
      "     |          Accordingly dataset is selected.\n",
      "     |      target_type (string or list, optional): Type of target to use, ``attr``, ``identity``, ``bbox``,\n",
      "     |          or ``landmarks``. Can also be a list to output a tuple with all specified target types.\n",
      "     |          The targets represent:\n",
      "     |  \n",
      "     |              - ``attr`` (np.array shape=(40,) dtype=int): binary (0, 1) labels for attributes\n",
      "     |              - ``identity`` (int): label for each person (data points with the same identity are the same person)\n",
      "     |              - ``bbox`` (np.array shape=(4,) dtype=int): bounding box (x, y, width, height)\n",
      "     |              - ``landmarks`` (np.array shape=(10,) dtype=int): landmark points (lefteye_x, lefteye_y, righteye_x,\n",
      "     |                righteye_y, nose_x, nose_y, leftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y)\n",
      "     |  \n",
      "     |          Defaults to ``attr``. If empty, ``None`` will be returned as target.\n",
      "     |  \n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.PILToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CelebA\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', target_type: Union[List[str], str] = 'attr', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  base_folder = 'celeba'\n",
      "     |  \n",
      "     |  file_list = [('0B7EVK8r0v71pZjFTYXZWM3FlRnM', '00d2c5bc6d35e252742224a...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Cityscapes(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Cityscapes(root: str, split: str = 'train', mode: str = 'fine', target_type: Union[List[str], str] = 'instance', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  `Cityscapes <http://www.cityscapes-dataset.com/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory ``leftImg8bit``\n",
      "     |          and ``gtFine`` or ``gtCoarse`` are located.\n",
      "     |      split (string, optional): The image split to use, ``train``, ``test`` or ``val`` if mode=\"fine\"\n",
      "     |          otherwise ``train``, ``train_extra`` or ``val``\n",
      "     |      mode (string, optional): The quality mode to use, ``fine`` or ``coarse``\n",
      "     |      target_type (string or list, optional): Type of target to use, ``instance``, ``semantic``, ``polygon``\n",
      "     |          or ``color``. Can also be a list to output a tuple with all specified target types.\n",
      "     |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |  \n",
      "     |      Get semantic segmentation target\n",
      "     |  \n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          dataset = Cityscapes('./data/cityscapes', split='train', mode='fine',\n",
      "     |                               target_type='semantic')\n",
      "     |  \n",
      "     |          img, smnt = dataset[0]\n",
      "     |  \n",
      "     |      Get multiple targets\n",
      "     |  \n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          dataset = Cityscapes('./data/cityscapes', split='train', mode='fine',\n",
      "     |                               target_type=['instance', 'color', 'polygon'])\n",
      "     |  \n",
      "     |          img, (inst, col, poly) = dataset[0]\n",
      "     |  \n",
      "     |      Validate on the \"coarse\" set\n",
      "     |  \n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          dataset = Cityscapes('./data/cityscapes', split='val', mode='coarse',\n",
      "     |                               target_type='semantic')\n",
      "     |  \n",
      "     |          img, smnt = dataset[0]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Cityscapes\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is a tuple of all target types if target_type is a list with more\n",
      "     |          than one item. Otherwise target is a json object if target_type=\"polygon\", else the image segmentation.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', mode: str = 'fine', target_type: Union[List[str], str] = 'instance', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CityscapesClass = <class 'torchvision.datasets.cityscapes.CityscapesCl...\n",
      "     |      CityscapesClass(name, id, train_id, category, category_id, has_instances, ignore_in_eval, color)\n",
      "     |  \n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = [CityscapesClass(name='unlabeled', id=0, train_id...nces=Fal...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class CocoCaptions(CocoDetection)\n",
      "     |  CocoCaptions(root: str, annFile: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  `MS Coco Captions <https://cocodataset.org/#captions-2015>`_ Dataset.\n",
      "     |  \n",
      "     |  It requires the `COCO API to be installed <https://github.com/pdollar/coco/tree/master/PythonAPI>`_.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      annFile (string): Path to json annotation file.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.PILToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |      .. code:: python\n",
      "     |  \n",
      "     |          import torchvision.datasets as dset\n",
      "     |          import torchvision.transforms as transforms\n",
      "     |          cap = dset.CocoCaptions(root = 'dir where images are',\n",
      "     |                                  annFile = 'json annotation file',\n",
      "     |                                  transform=transforms.PILToTensor())\n",
      "     |  \n",
      "     |          print('Number of samples: ', len(cap))\n",
      "     |          img, target = cap[3] # load 4th sample\n",
      "     |  \n",
      "     |          print(\"Image Size: \", img.size())\n",
      "     |          print(target)\n",
      "     |  \n",
      "     |      Output: ::\n",
      "     |  \n",
      "     |          Number of samples: 82783\n",
      "     |          Image Size: (3L, 427L, 640L)\n",
      "     |          [u'A plane emitting smoke stream flying over a mountain.',\n",
      "     |          u'A plane darts across a bright blue sky behind a mountain covered in snow',\n",
      "     |          u'A plane leaves a contrail above the snowy mountain top.',\n",
      "     |          u'A mountain that has a plane flying overheard in the distance.',\n",
      "     |          u'A mountain view with a plume of smoke in the background']\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CocoCaptions\n",
      "     |      CocoDetection\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from CocoDetection:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, annFile: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class CocoDetection(torchvision.datasets.vision.VisionDataset)\n",
      "     |  CocoDetection(root: str, annFile: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  `MS Coco Detection <https://cocodataset.org/#detection-2016>`_ Dataset.\n",
      "     |  \n",
      "     |  It requires the `COCO API to be installed <https://github.com/pdollar/coco/tree/master/PythonAPI>`_.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      annFile (string): Path to json annotation file.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.PILToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CocoDetection\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, annFile: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Country211(torchvision.datasets.folder.ImageFolder)\n",
      "     |  Country211(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `The Country211 Data Set <https://github.com/openai/CLIP/blob/main/data/country211.md>`_ from OpenAI.\n",
      "     |  \n",
      "     |  This dataset was built by filtering the images from the YFCC100m dataset\n",
      "     |  that have GPS coordinate corresponding to a ISO-3166 country code. The\n",
      "     |  dataset is balanced by sampling 150 train images, 50 validation images, and\n",
      "     |  100 test images images for each country.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"valid\"`` and ``\"test\"``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``.\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and puts it into\n",
      "     |          ``root/country211/``. If dataset is already downloaded, it is not downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Country211\n",
      "     |      torchvision.datasets.folder.ImageFolder\n",
      "     |      torchvision.datasets.folder.DatasetFolder\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.folder.DatasetFolder:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (sample, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]\n",
      "     |      Find the class folders in a dataset structured as follows::\n",
      "     |      \n",
      "     |          directory/\n",
      "     |          ├── class_x\n",
      "     |          │   ├── xxx.ext\n",
      "     |          │   ├── xxy.ext\n",
      "     |          │   └── ...\n",
      "     |          │       └── xxz.ext\n",
      "     |          └── class_y\n",
      "     |              ├── 123.ext\n",
      "     |              ├── nsdf3.ext\n",
      "     |              └── ...\n",
      "     |              └── asd932_.ext\n",
      "     |      \n",
      "     |      This method can be overridden to only consider\n",
      "     |      a subset of classes, or to adapt to a different dataset directory structure.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory(str): Root directory path, corresponding to ``self.root``\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          FileNotFoundError: If ``dir`` has no class folders.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torchvision.datasets.folder.DatasetFolder:\n",
      "     |  \n",
      "     |  make_dataset(directory: str, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[str], bool]] = None) -> List[Tuple[str, int]]\n",
      "     |      Generates a list of samples of a form (path_to_sample, class).\n",
      "     |      \n",
      "     |      This can be overridden to e.g. read files from a compressed zip file instead of from the disk.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory (str): root dataset directory, corresponding to ``self.root``.\n",
      "     |          class_to_idx (Dict[str, int]): Dictionary mapping class name to class index.\n",
      "     |          extensions (optional): A list of allowed extensions.\n",
      "     |              Either extensions or is_valid_file should be passed. Defaults to None.\n",
      "     |          is_valid_file (optional): A function that takes path of a file\n",
      "     |              and checks if the file is a valid file\n",
      "     |              (used to check of corrupt files) both extensions and\n",
      "     |              is_valid_file should not be passed. Defaults to None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case ``class_to_idx`` is empty.\n",
      "     |          ValueError: In case ``extensions`` and ``is_valid_file`` are None or both are not None.\n",
      "     |          FileNotFoundError: In case no valid file was found for any class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          List[Tuple[str, int]]: samples of a form (path_to_sample, class)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class DTD(torchvision.datasets.vision.VisionDataset)\n",
      "     |  DTD(root: str, split: str = 'train', partition: int = 1, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Describable Textures Dataset (DTD) <https://www.robots.ox.ac.uk/~vgg/data/dtd/>`_.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"val\"``, or ``\"test\"``.\n",
      "     |      partition (int, optional): The dataset partition. Should be ``1 <= partition <= 10``. Defaults to ``1``.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |              The partition only changes which split each image belongs to. Thus, regardless of the selected\n",
      "     |              partition, combining all splits will result in all images.\n",
      "     |  \n",
      "     |      transform (callable, optional): A function/transform that  takes in a PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``.\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again. Default is False.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DTD\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', partition: int = 1, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class DatasetFolder(torchvision.datasets.vision.VisionDataset)\n",
      "     |  DatasetFolder(root: str, loader: Callable[[str], Any], extensions: Optional[Tuple[str, ...]] = None, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, is_valid_file: Optional[Callable[[str], bool]] = None) -> None\n",
      "     |  \n",
      "     |  A generic data loader.\n",
      "     |  \n",
      "     |  This default directory structure can be customized by overriding the\n",
      "     |  :meth:`find_classes` method.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory path.\n",
      "     |      loader (callable): A function to load a sample given its path.\n",
      "     |      extensions (tuple[string]): A list of allowed extensions.\n",
      "     |          both extensions and is_valid_file should not be passed.\n",
      "     |      transform (callable, optional): A function/transform that takes in\n",
      "     |          a sample and returns a transformed version.\n",
      "     |          E.g, ``transforms.RandomCrop`` for images.\n",
      "     |      target_transform (callable, optional): A function/transform that takes\n",
      "     |          in the target and transforms it.\n",
      "     |      is_valid_file (callable, optional): A function that takes path of a file\n",
      "     |          and check if the file is a valid file (used to check of corrupt files)\n",
      "     |          both extensions and is_valid_file should not be passed.\n",
      "     |  \n",
      "     |   Attributes:\n",
      "     |      classes (list): List of the class names sorted alphabetically.\n",
      "     |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "     |      samples (list): List of (sample path, class_index) tuples\n",
      "     |      targets (list): The class_index value for each image in the dataset\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DatasetFolder\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (sample, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, loader: Callable[[str], Any], extensions: Optional[Tuple[str, ...]] = None, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, is_valid_file: Optional[Callable[[str], bool]] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]\n",
      "     |      Find the class folders in a dataset structured as follows::\n",
      "     |      \n",
      "     |          directory/\n",
      "     |          ├── class_x\n",
      "     |          │   ├── xxx.ext\n",
      "     |          │   ├── xxy.ext\n",
      "     |          │   └── ...\n",
      "     |          │       └── xxz.ext\n",
      "     |          └── class_y\n",
      "     |              ├── 123.ext\n",
      "     |              ├── nsdf3.ext\n",
      "     |              └── ...\n",
      "     |              └── asd932_.ext\n",
      "     |      \n",
      "     |      This method can be overridden to only consider\n",
      "     |      a subset of classes, or to adapt to a different dataset directory structure.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory(str): Root directory path, corresponding to ``self.root``\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          FileNotFoundError: If ``dir`` has no class folders.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  make_dataset(directory: str, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[str], bool]] = None) -> List[Tuple[str, int]]\n",
      "     |      Generates a list of samples of a form (path_to_sample, class).\n",
      "     |      \n",
      "     |      This can be overridden to e.g. read files from a compressed zip file instead of from the disk.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory (str): root dataset directory, corresponding to ``self.root``.\n",
      "     |          class_to_idx (Dict[str, int]): Dictionary mapping class name to class index.\n",
      "     |          extensions (optional): A list of allowed extensions.\n",
      "     |              Either extensions or is_valid_file should be passed. Defaults to None.\n",
      "     |          is_valid_file (optional): A function that takes path of a file\n",
      "     |              and checks if the file is a valid file\n",
      "     |              (used to check of corrupt files) both extensions and\n",
      "     |              is_valid_file should not be passed. Defaults to None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case ``class_to_idx`` is empty.\n",
      "     |          ValueError: In case ``extensions`` and ``is_valid_file`` are None or both are not None.\n",
      "     |          FileNotFoundError: In case no valid file was found for any class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          List[Tuple[str, int]]: samples of a form (path_to_sample, class)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class EMNIST(MNIST)\n",
      "     |  EMNIST(root: str, split: str, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  `EMNIST <https://www.westernsydney.edu.au/bens/home/reproducible_research/emnist>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where ``EMNIST/raw/train-images-idx3-ubyte``\n",
      "     |          and  ``EMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
      "     |      split (string): The dataset has 6 different splits: ``byclass``, ``bymerge``,\n",
      "     |          ``balanced``, ``letters``, ``digits`` and ``mnist``. This argument specifies\n",
      "     |          which one to use.\n",
      "     |      train (bool, optional): If True, creates dataset from ``training.pt``,\n",
      "     |          otherwise from ``test.pt``.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EMNIST\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the EMNIST data if it doesn't exist already.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  images_file\n",
      "     |  \n",
      "     |  labels_file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes_split_dict = {'balanced': ['0', '1', '2', '3', '4', '5', '6', ...\n",
      "     |  \n",
      "     |  md5 = '58c8d27c78d21e728a6bc7b3cc06412e'\n",
      "     |  \n",
      "     |  splits = ('byclass', 'bymerge', 'balanced', 'letters', 'digits', 'mnis...\n",
      "     |  \n",
      "     |  url = 'https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MNIST:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from MNIST:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from MNIST:\n",
      "     |  \n",
      "     |  classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', ...\n",
      "     |  \n",
      "     |  mirrors = ['http://yann.lecun.com/exdb/mnist/', 'https://ossci-dataset...\n",
      "     |  \n",
      "     |  resources = [('train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbd...\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class ETH3DStereo(StereoMatchingDataset)\n",
      "     |  ETH3DStereo(root: str, split: str = 'train', transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  ETH3D `Low-Res Two-View <https://www.eth3d.net/datasets>`_ dataset.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          ETH3D\n",
      "     |              two_view_training\n",
      "     |                  scene1\n",
      "     |                      im1.png\n",
      "     |                      im0.png\n",
      "     |                      images.txt\n",
      "     |                      cameras.txt\n",
      "     |                      calib.txt\n",
      "     |                  scene2\n",
      "     |                      im1.png\n",
      "     |                      im0.png\n",
      "     |                      images.txt\n",
      "     |                      cameras.txt\n",
      "     |                      calib.txt\n",
      "     |                  ...\n",
      "     |              two_view_training_gt\n",
      "     |                  scene1\n",
      "     |                      disp0GT.pfm\n",
      "     |                      mask0nocc.png\n",
      "     |                  scene2\n",
      "     |                      disp0GT.pfm\n",
      "     |                      mask0nocc.png\n",
      "     |                  ...\n",
      "     |              two_view_testing\n",
      "     |                  scene1\n",
      "     |                      im1.png\n",
      "     |                      im0.png\n",
      "     |                      images.txt\n",
      "     |                      cameras.txt\n",
      "     |                      calib.txt\n",
      "     |                  scene2\n",
      "     |                      im1.png\n",
      "     |                      im0.png\n",
      "     |                      images.txt\n",
      "     |                      cameras.txt\n",
      "     |                      calib.txt\n",
      "     |                  ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the ETH3D Dataset.\n",
      "     |      split (string, optional): The dataset split of scenes, either \"train\" (default) or \"test\".\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ETH3DStereo\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 4-tuple with ``(img_left, img_right, disparity, valid_mask)``.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images.\n",
      "     |          ``valid_mask`` is implicitly ``None`` if the ``transforms`` parameter does not\n",
      "     |          generate a valid mask.\n",
      "     |          Both ``disparity`` and ``valid_mask`` are ``None`` if the dataset split is test.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transforms: Optional[Callable] = None)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class EuroSAT(torchvision.datasets.folder.ImageFolder)\n",
      "     |  EuroSAT(root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  RGB version of the `EuroSAT <https://github.com/phelber/eurosat>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where ``root/eurosat`` exists.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again. Default is False.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      EuroSAT\n",
      "     |      torchvision.datasets.folder.ImageFolder\n",
      "     |      torchvision.datasets.folder.DatasetFolder\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.folder.DatasetFolder:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (sample, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]\n",
      "     |      Find the class folders in a dataset structured as follows::\n",
      "     |      \n",
      "     |          directory/\n",
      "     |          ├── class_x\n",
      "     |          │   ├── xxx.ext\n",
      "     |          │   ├── xxy.ext\n",
      "     |          │   └── ...\n",
      "     |          │       └── xxz.ext\n",
      "     |          └── class_y\n",
      "     |              ├── 123.ext\n",
      "     |              ├── nsdf3.ext\n",
      "     |              └── ...\n",
      "     |              └── asd932_.ext\n",
      "     |      \n",
      "     |      This method can be overridden to only consider\n",
      "     |      a subset of classes, or to adapt to a different dataset directory structure.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory(str): Root directory path, corresponding to ``self.root``\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          FileNotFoundError: If ``dir`` has no class folders.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torchvision.datasets.folder.DatasetFolder:\n",
      "     |  \n",
      "     |  make_dataset(directory: str, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[str], bool]] = None) -> List[Tuple[str, int]]\n",
      "     |      Generates a list of samples of a form (path_to_sample, class).\n",
      "     |      \n",
      "     |      This can be overridden to e.g. read files from a compressed zip file instead of from the disk.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory (str): root dataset directory, corresponding to ``self.root``.\n",
      "     |          class_to_idx (Dict[str, int]): Dictionary mapping class name to class index.\n",
      "     |          extensions (optional): A list of allowed extensions.\n",
      "     |              Either extensions or is_valid_file should be passed. Defaults to None.\n",
      "     |          is_valid_file (optional): A function that takes path of a file\n",
      "     |              and checks if the file is a valid file\n",
      "     |              (used to check of corrupt files) both extensions and\n",
      "     |              is_valid_file should not be passed. Defaults to None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case ``class_to_idx`` is empty.\n",
      "     |          ValueError: In case ``extensions`` and ``is_valid_file`` are None or both are not None.\n",
      "     |          FileNotFoundError: In case no valid file was found for any class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          List[Tuple[str, int]]: samples of a form (path_to_sample, class)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class FER2013(torchvision.datasets.vision.VisionDataset)\n",
      "     |  FER2013(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  `FER2013\n",
      "     |  <https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``root/fer2013`` exists.\n",
      "     |      split (string, optional): The dataset split, supports ``\"train\"`` (default), or ``\"test\"``.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FER2013\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class FGVCAircraft(torchvision.datasets.vision.VisionDataset)\n",
      "     |  FGVCAircraft(root: 'str', split: 'str' = 'trainval', annotation_level: 'str' = 'variant', transform: 'Optional[Callable]' = None, target_transform: 'Optional[Callable]' = None, download: 'bool' = False) -> 'None'\n",
      "     |  \n",
      "     |  `FGVC Aircraft <https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/>`_ Dataset.\n",
      "     |  \n",
      "     |  The dataset contains 10,000 images of aircraft, with 100 images for each of 100\n",
      "     |  different aircraft model variants, most of which are airplanes.\n",
      "     |  Aircraft models are organized in a three-levels hierarchy. The three levels, from\n",
      "     |  finer to coarser, are:\n",
      "     |  \n",
      "     |  - ``variant``, e.g. Boeing 737-700. A variant collapses all the models that are visually\n",
      "     |      indistinguishable into one class. The dataset comprises 100 different variants.\n",
      "     |  - ``family``, e.g. Boeing 737. The dataset comprises 70 different families.\n",
      "     |  - ``manufacturer``, e.g. Boeing. The dataset comprises 30 different manufacturers.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the FGVC Aircraft dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``train``, ``val``,\n",
      "     |          ``trainval`` and ``test``.\n",
      "     |      annotation_level (str, optional): The annotation level, supports ``variant``,\n",
      "     |          ``family`` and ``manufacturer``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FGVCAircraft\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx) -> 'Tuple[Any, Any]'\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: 'str', split: 'str' = 'trainval', annotation_level: 'str' = 'variant', transform: 'Optional[Callable]' = None, target_transform: 'Optional[Callable]' = None, download: 'bool' = False) -> 'None'\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> 'int'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class FakeData(torchvision.datasets.vision.VisionDataset)\n",
      "     |  FakeData(size: int = 1000, image_size: Tuple[int, int, int] = (3, 224, 224), num_classes: int = 10, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, random_offset: int = 0) -> None\n",
      "     |  \n",
      "     |  A fake dataset that returns randomly generated images and returns them as PIL images\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      size (int, optional): Size of the dataset. Default: 1000 images\n",
      "     |      image_size(tuple, optional): Size if the returned images. Default: (3, 224, 224)\n",
      "     |      num_classes(int, optional): Number of classes in the dataset. Default: 10\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      random_offset (int): Offsets the index-based random seed used to\n",
      "     |          generate each image. Default: 0\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FakeData\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, size: int = 1000, image_size: Tuple[int, int, int] = (3, 224, 224), num_classes: int = 10, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, random_offset: int = 0) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class FallingThingsStereo(StereoMatchingDataset)\n",
      "     |  FallingThingsStereo(root: str, variant: str = 'single', transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  `FallingThings <https://research.nvidia.com/publication/2018-06_falling-things-synthetic-dataset-3d-object-detection-and-pose-estimation>`_ dataset.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structre: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          FallingThings\n",
      "     |              single\n",
      "     |                  dir1\n",
      "     |                      scene1\n",
      "     |                          _object_settings.json\n",
      "     |                          _camera_settings.json\n",
      "     |                          image1.left.depth.png\n",
      "     |                          image1.right.depth.png\n",
      "     |                          image1.left.jpg\n",
      "     |                          image1.right.jpg\n",
      "     |                          image2.left.depth.png\n",
      "     |                          image2.right.depth.png\n",
      "     |                          image2.left.jpg\n",
      "     |                          image2.right\n",
      "     |                          ...\n",
      "     |                      scene2\n",
      "     |                  ...\n",
      "     |              mixed\n",
      "     |                  scene1\n",
      "     |                      _object_settings.json\n",
      "     |                      _camera_settings.json\n",
      "     |                      image1.left.depth.png\n",
      "     |                      image1.right.depth.png\n",
      "     |                      image1.left.jpg\n",
      "     |                      image1.right.jpg\n",
      "     |                      image2.left.depth.png\n",
      "     |                      image2.right.depth.png\n",
      "     |                      image2.left.jpg\n",
      "     |                      image2.right\n",
      "     |                      ...\n",
      "     |                  scene2\n",
      "     |                  ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where FallingThings is located.\n",
      "     |      variant (string): Which variant to use. Either \"single\", \"mixed\", or \"both\".\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FallingThingsStereo\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 3-tuple with ``(img_left, img_right, disparity)``.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images.\n",
      "     |          If a ``valid_mask`` is generated within the ``transforms`` parameter,\n",
      "     |          a 4-tuple with ``(img_left, img_right, disparity, valid_mask)`` is returned.\n",
      "     |  \n",
      "     |  __init__(self, root: str, variant: str = 'single', transforms: Optional[Callable] = None)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class FashionMNIST(MNIST)\n",
      "     |  FashionMNIST(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
      "     |          and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
      "     |      train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
      "     |          otherwise from ``t10k-images-idx3-ubyte``.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FashionMNIST\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'San...\n",
      "     |  \n",
      "     |  mirrors = ['http://fashion-mnist.s3-website.eu-central-1.amazonaws.com...\n",
      "     |  \n",
      "     |  resources = [('train-images-idx3-ubyte.gz', '8d4fb7e6c68d591d4c3dfef9e...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MNIST:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the MNIST data if it doesn't exist already.\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from MNIST:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from MNIST:\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Flickr30k(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Flickr30k(root: str, ann_file: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  `Flickr30k Entities <https://bryanplummer.com/Flickr30kEntities/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      ann_file (string): Path to annotation file.\n",
      "     |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.PILToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Flickr30k\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: Tuple (image, target). target is a list of captions for the image.\n",
      "     |  \n",
      "     |  __init__(self, root: str, ann_file: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Flickr8k(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Flickr8k(root: str, ann_file: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  `Flickr8k Entities <http://hockenmaier.cs.illinois.edu/8k-pictures.html>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |      ann_file (string): Path to annotation file.\n",
      "     |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.PILToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Flickr8k\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: Tuple (image, target). target is a list of captions for the image.\n",
      "     |  \n",
      "     |  __init__(self, root: str, ann_file: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Flowers102(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Flowers102(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Oxford 102 Flower <https://www.robots.ox.ac.uk/~vgg/data/flowers/102/>`_ Dataset.\n",
      "     |  \n",
      "     |  .. warning::\n",
      "     |  \n",
      "     |      This class needs `scipy <https://docs.scipy.org/doc/>`_ to load target files from `.mat` format.\n",
      "     |  \n",
      "     |  Oxford 102 Flower is an image classification dataset consisting of 102 flower categories. The\n",
      "     |  flowers were chosen to be flowers commonly occurring in the United Kingdom. Each class consists of\n",
      "     |  between 40 and 258 images.\n",
      "     |  \n",
      "     |  The images have large scale, pose and light variations. In addition, there are categories that\n",
      "     |  have large variations within the category, and several very similar categories.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"val\"``, or ``\"test\"``.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image and returns a\n",
      "     |          transformed version. E.g, ``transforms.RandomCrop``.\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Flowers102\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self)\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class FlyingChairs(FlowDataset)\n",
      "     |  FlyingChairs(root, split='train', transforms=None)\n",
      "     |  \n",
      "     |  `FlyingChairs <https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html#flyingchairs>`_ Dataset for optical flow.\n",
      "     |  \n",
      "     |  You will also need to download the FlyingChairs_train_val.txt file from the dataset page.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          FlyingChairs\n",
      "     |              data\n",
      "     |                  00001_flow.flo\n",
      "     |                  00001_img1.ppm\n",
      "     |                  00001_img2.ppm\n",
      "     |                  ...\n",
      "     |              FlyingChairs_train_val.txt\n",
      "     |  \n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the FlyingChairs Dataset.\n",
      "     |      split (string, optional): The dataset split, either \"train\" (default) or \"val\"\n",
      "     |      transforms (callable, optional): A function/transform that takes in\n",
      "     |          ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n",
      "     |          ``valid_flow_mask`` is expected for consistency with other datasets which\n",
      "     |          return a built-in valid mask, such as :class:`~torchvision.datasets.KittiFlow`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FlyingChairs\n",
      "     |      FlowDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 3-tuple with ``(img1, img2, flow)``.\n",
      "     |          The flow is a numpy array of shape (2, H, W) and the images are PIL images.\n",
      "     |          ``flow`` is None if ``split=\"val\"``.\n",
      "     |          If a valid flow mask is generated within the ``transforms`` parameter,\n",
      "     |          a 4-tuple with ``(img1, img2, flow, valid_flow_mask)`` is returned.\n",
      "     |  \n",
      "     |  __init__(self, root, split='train', transforms=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __rmul__(self, v)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class FlyingThings3D(FlowDataset)\n",
      "     |  FlyingThings3D(root, split='train', pass_name='clean', camera='left', transforms=None)\n",
      "     |  \n",
      "     |  `FlyingThings3D <https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html>`_ dataset for optical flow.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          FlyingThings3D\n",
      "     |              frames_cleanpass\n",
      "     |                  TEST\n",
      "     |                  TRAIN\n",
      "     |              frames_finalpass\n",
      "     |                  TEST\n",
      "     |                  TRAIN\n",
      "     |              optical_flow\n",
      "     |                  TEST\n",
      "     |                  TRAIN\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the intel FlyingThings3D Dataset.\n",
      "     |      split (string, optional): The dataset split, either \"train\" (default) or \"test\"\n",
      "     |      pass_name (string, optional): The pass to use, either \"clean\" (default) or \"final\" or \"both\". See link above for\n",
      "     |          details on the different passes.\n",
      "     |      camera (string, optional): Which camera to return images from. Can be either \"left\" (default) or \"right\" or \"both\".\n",
      "     |      transforms (callable, optional): A function/transform that takes in\n",
      "     |          ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n",
      "     |          ``valid_flow_mask`` is expected for consistency with other datasets which\n",
      "     |          return a built-in valid mask, such as :class:`~torchvision.datasets.KittiFlow`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FlyingThings3D\n",
      "     |      FlowDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 3-tuple with ``(img1, img2, flow)``.\n",
      "     |          The flow is a numpy array of shape (2, H, W) and the images are PIL images.\n",
      "     |          ``flow`` is None if ``split=\"test\"``.\n",
      "     |          If a valid flow mask is generated within the ``transforms`` parameter,\n",
      "     |          a 4-tuple with ``(img1, img2, flow, valid_flow_mask)`` is returned.\n",
      "     |  \n",
      "     |  __init__(self, root, split='train', pass_name='clean', camera='left', transforms=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __rmul__(self, v)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Food101(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Food101(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `The Food-101 Data Set <https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/>`_.\n",
      "     |  \n",
      "     |  The Food-101 is a challenging data set of 101 food categories with 101,000 images.\n",
      "     |  For each class, 250 manually reviewed test images are provided as well as 750 training images.\n",
      "     |  On purpose, the training images were not cleaned, and thus still contain some amount of noise.\n",
      "     |  This comes mostly in the form of intense colors and sometimes wrong labels. All images were\n",
      "     |  rescaled to have a maximum side length of 512 pixels.\n",
      "     |  \n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``\"train\"`` (default) and ``\"test\"``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``.\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again. Default is False.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Food101\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class GTSRB(torchvision.datasets.vision.VisionDataset)\n",
      "     |  GTSRB(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `German Traffic Sign Recognition Benchmark (GTSRB) <https://benchmark.ini.rub.de/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``\"train\"`` (default), or ``\"test\"``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``.\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GTSRB\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class HD1K(FlowDataset)\n",
      "     |  HD1K(root, split='train', transforms=None)\n",
      "     |  \n",
      "     |  `HD1K <http://hci-benchmark.iwr.uni-heidelberg.de/>`__ dataset for optical flow.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          hd1k\n",
      "     |              hd1k_challenge\n",
      "     |                  image_2\n",
      "     |              hd1k_flow_gt\n",
      "     |                  flow_occ\n",
      "     |              hd1k_input\n",
      "     |                  image_2\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the HD1K Dataset.\n",
      "     |      split (string, optional): The dataset split, either \"train\" (default) or \"test\"\n",
      "     |      transforms (callable, optional): A function/transform that takes in\n",
      "     |          ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HD1K\n",
      "     |      FlowDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 4-tuple with ``(img1, img2, flow, valid_flow_mask)`` where ``valid_flow_mask``\n",
      "     |          is a numpy boolean mask of shape (H, W)\n",
      "     |          indicating which flow values are valid. The flow is a numpy array of\n",
      "     |          shape (2, H, W) and the images are PIL images. ``flow`` and ``valid_flow_mask`` are None if\n",
      "     |          ``split=\"test\"``.\n",
      "     |  \n",
      "     |  __init__(self, root, split='train', transforms=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __rmul__(self, v)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class HMDB51(torchvision.datasets.vision.VisionDataset)\n",
      "     |  HMDB51(root: str, annotation_path: str, frames_per_clip: int, step_between_clips: int = 1, frame_rate: Optional[int] = None, fold: int = 1, train: bool = True, transform: Optional[Callable] = None, _precomputed_metadata: Optional[Dict[str, Any]] = None, num_workers: int = 1, _video_width: int = 0, _video_height: int = 0, _video_min_dimension: int = 0, _audio_samples: int = 0, output_format: str = 'THWC') -> None\n",
      "     |  \n",
      "     |  `HMDB51 <https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/>`_\n",
      "     |  dataset.\n",
      "     |  \n",
      "     |  HMDB51 is an action recognition video dataset.\n",
      "     |  This dataset consider every video as a collection of video clips of fixed size, specified\n",
      "     |  by ``frames_per_clip``, where the step in frames between each clip is given by\n",
      "     |  ``step_between_clips``.\n",
      "     |  \n",
      "     |  To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``\n",
      "     |  and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two\n",
      "     |  elements will come from video 1, and the next three elements from video 2.\n",
      "     |  Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all\n",
      "     |  frames in a video might be present.\n",
      "     |  \n",
      "     |  Internally, it uses a VideoClips object to handle clip creation.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the HMDB51 Dataset.\n",
      "     |      annotation_path (str): Path to the folder containing the split files.\n",
      "     |      frames_per_clip (int): Number of frames in a clip.\n",
      "     |      step_between_clips (int): Number of frames between each clip.\n",
      "     |      fold (int, optional): Which fold to use. Should be between 1 and 3.\n",
      "     |      train (bool, optional): If ``True``, creates a dataset from the train split,\n",
      "     |          otherwise from the ``test`` split.\n",
      "     |      transform (callable, optional): A function/transform that takes in a TxHxWxC video\n",
      "     |          and returns a transformed version.\n",
      "     |      output_format (str, optional): The format of the output video tensors (before transforms).\n",
      "     |          Can be either \"THWC\" (default) or \"TCHW\".\n",
      "     |  \n",
      "     |  Returns:\n",
      "     |      tuple: A 3-tuple with the following entries:\n",
      "     |  \n",
      "     |          - video (Tensor[T, H, W, C] or Tensor[T, C, H, W]): The `T` video frames\n",
      "     |          - audio(Tensor[K, L]): the audio frames, where `K` is the number of channels\n",
      "     |            and `L` is the number of points\n",
      "     |          - label (int): class of the video clip\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HMDB51\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, annotation_path: str, frames_per_clip: int, step_between_clips: int = 1, frame_rate: Optional[int] = None, fold: int = 1, train: bool = True, transform: Optional[Callable] = None, _precomputed_metadata: Optional[Dict[str, Any]] = None, num_workers: int = 1, _video_width: int = 0, _video_height: int = 0, _video_min_dimension: int = 0, _audio_samples: int = 0, output_format: str = 'THWC') -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  metadata\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  TEST_TAG = 2\n",
      "     |  \n",
      "     |  TRAIN_TAG = 1\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  data_url = 'https://serre-lab.clps.brown.edu/wp-content/uploads/2013/1...\n",
      "     |  \n",
      "     |  splits = {'md5': '15e67781e70dcfbdce2d7dbb9b3344b5', 'url': 'https://s...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class INaturalist(torchvision.datasets.vision.VisionDataset)\n",
      "     |  INaturalist(root: str, version: str = '2021_train', target_type: Union[List[str], str] = 'full', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `iNaturalist <https://github.com/visipedia/inat_comp>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where the image files are stored.\n",
      "     |          This class does not require/use annotation files.\n",
      "     |      version (string, optional): Which version of the dataset to download/use. One of\n",
      "     |          '2017', '2018', '2019', '2021_train', '2021_train_mini', '2021_valid'.\n",
      "     |          Default: `2021_train`.\n",
      "     |      target_type (string or list, optional): Type of target to use, for 2021 versions, one of:\n",
      "     |  \n",
      "     |          - ``full``: the full category (species)\n",
      "     |          - ``kingdom``: e.g. \"Animalia\"\n",
      "     |          - ``phylum``: e.g. \"Arthropoda\"\n",
      "     |          - ``class``: e.g. \"Insecta\"\n",
      "     |          - ``order``: e.g. \"Coleoptera\"\n",
      "     |          - ``family``: e.g. \"Cleridae\"\n",
      "     |          - ``genus``: e.g. \"Trichodes\"\n",
      "     |  \n",
      "     |          for 2017-2019 versions, one of:\n",
      "     |  \n",
      "     |          - ``full``: the full (numeric) category\n",
      "     |          - ``super``: the super category, e.g. \"Amphibians\"\n",
      "     |  \n",
      "     |          Can also be a list to output a tuple with all specified target types.\n",
      "     |          Defaults to ``full``.\n",
      "     |      transform (callable, optional): A function/transform that takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      INaturalist\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where the type of target specified by target_type.\n",
      "     |  \n",
      "     |  __init__(self, root: str, version: str = '2021_train', target_type: Union[List[str], str] = 'full', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  category_name(self, category_type: str, category_id: int) -> str\n",
      "     |      Args:\n",
      "     |          category_type(str): one of \"full\", \"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\" or \"super\"\n",
      "     |          category_id(int): an index (class id) from this category\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          the name of the category\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class ImageFolder(DatasetFolder)\n",
      "     |  ImageFolder(root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = <function default_loader at 0x00000205DAF38430>, is_valid_file: Optional[Callable[[str], bool]] = None)\n",
      "     |  \n",
      "     |  A generic data loader where the images are arranged in this way by default: ::\n",
      "     |  \n",
      "     |      root/dog/xxx.png\n",
      "     |      root/dog/xxy.png\n",
      "     |      root/dog/[...]/xxz.png\n",
      "     |  \n",
      "     |      root/cat/123.png\n",
      "     |      root/cat/nsdf3.png\n",
      "     |      root/cat/[...]/asd932_.png\n",
      "     |  \n",
      "     |  This class inherits from :class:`~torchvision.datasets.DatasetFolder` so\n",
      "     |  the same methods can be overridden to customize the dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory path.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      loader (callable, optional): A function to load an image given its path.\n",
      "     |      is_valid_file (callable, optional): A function that takes path of an Image file\n",
      "     |          and check if the file is a valid file (used to check of corrupt files)\n",
      "     |  \n",
      "     |   Attributes:\n",
      "     |      classes (list): List of the class names sorted alphabetically.\n",
      "     |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "     |      imgs (list): List of (image path, class_index) tuples\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ImageFolder\n",
      "     |      DatasetFolder\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = <function default_loader at 0x00000205DAF38430>, is_valid_file: Optional[Callable[[str], bool]] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DatasetFolder:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (sample, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]\n",
      "     |      Find the class folders in a dataset structured as follows::\n",
      "     |      \n",
      "     |          directory/\n",
      "     |          ├── class_x\n",
      "     |          │   ├── xxx.ext\n",
      "     |          │   ├── xxy.ext\n",
      "     |          │   └── ...\n",
      "     |          │       └── xxz.ext\n",
      "     |          └── class_y\n",
      "     |              ├── 123.ext\n",
      "     |              ├── nsdf3.ext\n",
      "     |              └── ...\n",
      "     |              └── asd932_.ext\n",
      "     |      \n",
      "     |      This method can be overridden to only consider\n",
      "     |      a subset of classes, or to adapt to a different dataset directory structure.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory(str): Root directory path, corresponding to ``self.root``\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          FileNotFoundError: If ``dir`` has no class folders.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from DatasetFolder:\n",
      "     |  \n",
      "     |  make_dataset(directory: str, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[str], bool]] = None) -> List[Tuple[str, int]]\n",
      "     |      Generates a list of samples of a form (path_to_sample, class).\n",
      "     |      \n",
      "     |      This can be overridden to e.g. read files from a compressed zip file instead of from the disk.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory (str): root dataset directory, corresponding to ``self.root``.\n",
      "     |          class_to_idx (Dict[str, int]): Dictionary mapping class name to class index.\n",
      "     |          extensions (optional): A list of allowed extensions.\n",
      "     |              Either extensions or is_valid_file should be passed. Defaults to None.\n",
      "     |          is_valid_file (optional): A function that takes path of a file\n",
      "     |              and checks if the file is a valid file\n",
      "     |              (used to check of corrupt files) both extensions and\n",
      "     |              is_valid_file should not be passed. Defaults to None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case ``class_to_idx`` is empty.\n",
      "     |          ValueError: In case ``extensions`` and ``is_valid_file`` are None or both are not None.\n",
      "     |          FileNotFoundError: In case no valid file was found for any class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          List[Tuple[str, int]]: samples of a form (path_to_sample, class)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class ImageNet(torchvision.datasets.folder.ImageFolder)\n",
      "     |  ImageNet(root: str, split: str = 'train', **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  `ImageNet <http://image-net.org/>`_ 2012 Classification Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the ImageNet Dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``train``, or ``val``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      loader (callable, optional): A function to load an image given its path.\n",
      "     |  \n",
      "     |   Attributes:\n",
      "     |      classes (list): List of the class name tuples.\n",
      "     |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "     |      wnids (list): List of the WordNet IDs.\n",
      "     |      wnid_to_idx (dict): Dict with items (wordnet_id, class_index).\n",
      "     |      imgs (list): List of (image path, class_index) tuples\n",
      "     |      targets (list): The class_index value for each image in the dataset\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ImageNet\n",
      "     |      torchvision.datasets.folder.ImageFolder\n",
      "     |      torchvision.datasets.folder.DatasetFolder\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  parse_archives(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  split_folder\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.folder.DatasetFolder:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (sample, target) where target is class_index of the target class.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]\n",
      "     |      Find the class folders in a dataset structured as follows::\n",
      "     |      \n",
      "     |          directory/\n",
      "     |          ├── class_x\n",
      "     |          │   ├── xxx.ext\n",
      "     |          │   ├── xxy.ext\n",
      "     |          │   └── ...\n",
      "     |          │       └── xxz.ext\n",
      "     |          └── class_y\n",
      "     |              ├── 123.ext\n",
      "     |              ├── nsdf3.ext\n",
      "     |              └── ...\n",
      "     |              └── asd932_.ext\n",
      "     |      \n",
      "     |      This method can be overridden to only consider\n",
      "     |      a subset of classes, or to adapt to a different dataset directory structure.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory(str): Root directory path, corresponding to ``self.root``\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          FileNotFoundError: If ``dir`` has no class folders.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torchvision.datasets.folder.DatasetFolder:\n",
      "     |  \n",
      "     |  make_dataset(directory: str, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[str], bool]] = None) -> List[Tuple[str, int]]\n",
      "     |      Generates a list of samples of a form (path_to_sample, class).\n",
      "     |      \n",
      "     |      This can be overridden to e.g. read files from a compressed zip file instead of from the disk.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          directory (str): root dataset directory, corresponding to ``self.root``.\n",
      "     |          class_to_idx (Dict[str, int]): Dictionary mapping class name to class index.\n",
      "     |          extensions (optional): A list of allowed extensions.\n",
      "     |              Either extensions or is_valid_file should be passed. Defaults to None.\n",
      "     |          is_valid_file (optional): A function that takes path of a file\n",
      "     |              and checks if the file is a valid file\n",
      "     |              (used to check of corrupt files) both extensions and\n",
      "     |              is_valid_file should not be passed. Defaults to None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: In case ``class_to_idx`` is empty.\n",
      "     |          ValueError: In case ``extensions`` and ``is_valid_file`` are None or both are not None.\n",
      "     |          FileNotFoundError: In case no valid file was found for any class.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          List[Tuple[str, int]]: samples of a form (path_to_sample, class)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class InStereo2k(StereoMatchingDataset)\n",
      "     |  InStereo2k(root: str, split: str = 'train', transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  `InStereo2k <https://github.com/YuhuaXu/StereoDataset>`_ dataset.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structre: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          InStereo2k\n",
      "     |              train\n",
      "     |                  scene1\n",
      "     |                      left.png\n",
      "     |                      right.png\n",
      "     |                      left_disp.png\n",
      "     |                      right_disp.png\n",
      "     |                      ...\n",
      "     |                  scene2\n",
      "     |                  ...\n",
      "     |              test\n",
      "     |                  scene1\n",
      "     |                      left.png\n",
      "     |                      right.png\n",
      "     |                      left_disp.png\n",
      "     |                      right_disp.png\n",
      "     |                      ...\n",
      "     |                  scene2\n",
      "     |                  ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where InStereo2k is located.\n",
      "     |      split (string): Either \"train\" or \"test\".\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InStereo2k\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 3-tuple with ``(img_left, img_right, disparity)``.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images.\n",
      "     |          If a ``valid_mask`` is generated within the ``transforms`` parameter,\n",
      "     |          a 4-tuple with ``(img_left, img_right, disparity, valid_mask)`` is returned.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transforms: Optional[Callable] = None)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class KMNIST(MNIST)\n",
      "     |  KMNIST(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Kuzushiji-MNIST <https://github.com/rois-codh/kmnist>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where ``KMNIST/raw/train-images-idx3-ubyte``\n",
      "     |          and  ``KMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
      "     |      train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
      "     |          otherwise from ``t10k-images-idx3-ubyte``.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KMNIST\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = ['o', 'ki', 'su', 'tsu', 'na', 'ha', 'ma', 'ya', 're', 'wo']\n",
      "     |  \n",
      "     |  mirrors = ['http://codh.rois.ac.jp/kmnist/dataset/kmnist/']\n",
      "     |  \n",
      "     |  resources = [('train-images-idx3-ubyte.gz', 'bdb82020997e1d708af4cf47b...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MNIST:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the MNIST data if it doesn't exist already.\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from MNIST:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from MNIST:\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Kinetics(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Kinetics(root: str, frames_per_clip: int, num_classes: str = '400', split: str = 'train', frame_rate: Optional[int] = None, step_between_clips: int = 1, transform: Optional[Callable] = None, extensions: Tuple[str, ...] = ('avi', 'mp4'), download: bool = False, num_download_workers: int = 1, num_workers: int = 1, _precomputed_metadata: Optional[Dict[str, Any]] = None, _video_width: int = 0, _video_height: int = 0, _video_min_dimension: int = 0, _audio_samples: int = 0, _audio_channels: int = 0, _legacy: bool = False, output_format: str = 'TCHW') -> None\n",
      "     |  \n",
      "     |  `Generic Kinetics <https://www.deepmind.com/open-source/kinetics>`_\n",
      "     |  dataset.\n",
      "     |  \n",
      "     |  Kinetics-400/600/700 are action recognition video datasets.\n",
      "     |  This dataset consider every video as a collection of video clips of fixed size, specified\n",
      "     |  by ``frames_per_clip``, where the step in frames between each clip is given by\n",
      "     |  ``step_between_clips``.\n",
      "     |  \n",
      "     |  To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``\n",
      "     |  and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two\n",
      "     |  elements will come from video 1, and the next three elements from video 2.\n",
      "     |  Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all\n",
      "     |  frames in a video might be present.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the Kinetics Dataset.\n",
      "     |          Directory should be structured as follows:\n",
      "     |          .. code::\n",
      "     |  \n",
      "     |              root/\n",
      "     |              ├── split\n",
      "     |              │   ├──  class1\n",
      "     |              │   │   ├──  clip1.mp4\n",
      "     |              │   │   ├──  clip2.mp4\n",
      "     |              │   │   ├──  clip3.mp4\n",
      "     |              │   │   ├──  ...\n",
      "     |              │   ├──  class2\n",
      "     |              │   │   ├──   clipx.mp4\n",
      "     |              │   │    └── ...\n",
      "     |  \n",
      "     |          Note: split is appended automatically using the split argument.\n",
      "     |      frames_per_clip (int): number of frames in a clip\n",
      "     |      num_classes (int): select between Kinetics-400 (default), Kinetics-600, and Kinetics-700\n",
      "     |      split (str): split of the dataset to consider; supports ``\"train\"`` (default) ``\"val\"`` ``\"test\"``\n",
      "     |      frame_rate (float): If omitted, interpolate different frame rate for each clip.\n",
      "     |      step_between_clips (int): number of frames between each clip\n",
      "     |      transform (callable, optional): A function/transform that  takes in a TxHxWxC video\n",
      "     |          and returns a transformed version.\n",
      "     |      download (bool): Download the official version of the dataset to root folder.\n",
      "     |      num_workers (int): Use multiple workers for VideoClips creation\n",
      "     |      num_download_workers (int): Use multiprocessing in order to speed up download.\n",
      "     |      output_format (str, optional): The format of the output video tensors (before transforms).\n",
      "     |          Can be either \"THWC\" or \"TCHW\" (default).\n",
      "     |          Note that in most other utils and datasets, the default is actually \"THWC\".\n",
      "     |  \n",
      "     |  Returns:\n",
      "     |      tuple: A 3-tuple with the following entries:\n",
      "     |  \n",
      "     |          - video (Tensor[T, C, H, W] or Tensor[T, H, W, C]): the `T` video frames in torch.uint8 tensor\n",
      "     |          - audio(Tensor[K, L]): the audio frames, where `K` is the number of channels\n",
      "     |            and `L` is the number of points in torch.float tensor\n",
      "     |          - label (int): class of the video clip\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |      RuntimeError: If ``download is True`` and the video archives are already extracted.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Kinetics\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, frames_per_clip: int, num_classes: str = '400', split: str = 'train', frame_rate: Optional[int] = None, step_between_clips: int = 1, transform: Optional[Callable] = None, extensions: Tuple[str, ...] = ('avi', 'mp4'), download: bool = False, num_download_workers: int = 1, num_workers: int = 1, _precomputed_metadata: Optional[Dict[str, Any]] = None, _video_width: int = 0, _video_height: int = 0, _video_min_dimension: int = 0, _audio_samples: int = 0, _audio_channels: int = 0, _legacy: bool = False, output_format: str = 'TCHW') -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download_and_process_videos(self) -> None\n",
      "     |      Downloads all the videos to the _root_ folder in the expected format.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  metadata\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Kitti(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Kitti(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None, download: bool = False)\n",
      "     |  \n",
      "     |  `KITTI <http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark>`_ Dataset.\n",
      "     |  \n",
      "     |  It corresponds to the \"left color images of object\" dataset, for object detection.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are downloaded to.\n",
      "     |          Expects the following folder structure if download=False:\n",
      "     |  \n",
      "     |          .. code::\n",
      "     |  \n",
      "     |              <root>\n",
      "     |                  └── Kitti\n",
      "     |                      └─ raw\n",
      "     |                          ├── training\n",
      "     |                          |   ├── image_2\n",
      "     |                          |   └── label_2\n",
      "     |                          └── testing\n",
      "     |                              └── image_2\n",
      "     |      train (bool, optional): Use ``train`` split if true, else ``test`` split.\n",
      "     |          Defaults to ``train``.\n",
      "     |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.PILToTensor``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample\n",
      "     |          and its target as entry and returns a transformed version.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Kitti\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Get item at a given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      Returns:\n",
      "     |          tuple: (image, target), where\n",
      "     |          target is a list of dictionaries with the following keys:\n",
      "     |      \n",
      "     |          - type: str\n",
      "     |          - truncated: float\n",
      "     |          - occluded: int\n",
      "     |          - alpha: float\n",
      "     |          - bbox: float[4]\n",
      "     |          - dimensions: float[3]\n",
      "     |          - locations: float[3]\n",
      "     |          - rotation_y: float\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None, download: bool = False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the KITTI data if it doesn't exist already.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  data_url = 'https://s3.eu-central-1.amazonaws.com/avg-kitti/'\n",
      "     |  \n",
      "     |  image_dir_name = 'image_2'\n",
      "     |  \n",
      "     |  labels_dir_name = 'label_2'\n",
      "     |  \n",
      "     |  resources = ['data_object_image_2.zip', 'data_object_label_2.zip']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Kitti2012Stereo(StereoMatchingDataset)\n",
      "     |  Kitti2012Stereo(root: str, split: str = 'train', transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  KITTI dataset from the `2012 stereo evaluation benchmark <http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php>`_.\n",
      "     |  Uses the RGB images for consistency with KITTI 2015.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          Kitti2012\n",
      "     |              testing\n",
      "     |                  colored_0\n",
      "     |                      1_10.png\n",
      "     |                      2_10.png\n",
      "     |                      ...\n",
      "     |                  colored_1\n",
      "     |                      1_10.png\n",
      "     |                      2_10.png\n",
      "     |                      ...\n",
      "     |              training\n",
      "     |                  colored_0\n",
      "     |                      1_10.png\n",
      "     |                      2_10.png\n",
      "     |                      ...\n",
      "     |                  colored_1\n",
      "     |                      1_10.png\n",
      "     |                      2_10.png\n",
      "     |                      ...\n",
      "     |                  disp_noc\n",
      "     |                      1.png\n",
      "     |                      2.png\n",
      "     |                      ...\n",
      "     |                  calib\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where `Kitti2012` is located.\n",
      "     |      split (string, optional): The dataset split of scenes, either \"train\" (default) or \"test\".\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Kitti2012Stereo\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 4-tuple with ``(img_left, img_right, disparity, valid_mask)``.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images.\n",
      "     |          ``valid_mask`` is implicitly ``None`` if the ``transforms`` parameter does not\n",
      "     |          generate a valid mask.\n",
      "     |          Both ``disparity`` and ``valid_mask`` are ``None`` if the dataset split is test.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transforms: Optional[Callable] = None)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Kitti2015Stereo(StereoMatchingDataset)\n",
      "     |  Kitti2015Stereo(root: str, split: str = 'train', transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  KITTI dataset from the `2015 stereo evaluation benchmark <http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php>`_.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          Kitti2015\n",
      "     |              testing\n",
      "     |                  image_2\n",
      "     |                      img1.png\n",
      "     |                      img2.png\n",
      "     |                      ...\n",
      "     |                  image_3\n",
      "     |                      img1.png\n",
      "     |                      img2.png\n",
      "     |                      ...\n",
      "     |              training\n",
      "     |                  image_2\n",
      "     |                      img1.png\n",
      "     |                      img2.png\n",
      "     |                      ...\n",
      "     |                  image_3\n",
      "     |                      img1.png\n",
      "     |                      img2.png\n",
      "     |                      ...\n",
      "     |                  disp_occ_0\n",
      "     |                      img1.png\n",
      "     |                      img2.png\n",
      "     |                      ...\n",
      "     |                  disp_occ_1\n",
      "     |                      img1.png\n",
      "     |                      img2.png\n",
      "     |                      ...\n",
      "     |                  calib\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where `Kitti2015` is located.\n",
      "     |      split (string, optional): The dataset split of scenes, either \"train\" (default) or \"test\".\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Kitti2015Stereo\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 4-tuple with ``(img_left, img_right, disparity, valid_mask)``.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images.\n",
      "     |          ``valid_mask`` is implicitly ``None`` if the ``transforms`` parameter does not\n",
      "     |          generate a valid mask.\n",
      "     |          Both ``disparity`` and ``valid_mask`` are ``None`` if the dataset split is test.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transforms: Optional[Callable] = None)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class KittiFlow(FlowDataset)\n",
      "     |  KittiFlow(root, split='train', transforms=None)\n",
      "     |  \n",
      "     |  `KITTI <http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=flow>`__ dataset for optical flow (2015).\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          KittiFlow\n",
      "     |              testing\n",
      "     |                  image_2\n",
      "     |              training\n",
      "     |                  image_2\n",
      "     |                  flow_occ\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the KittiFlow Dataset.\n",
      "     |      split (string, optional): The dataset split, either \"train\" (default) or \"test\"\n",
      "     |      transforms (callable, optional): A function/transform that takes in\n",
      "     |          ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KittiFlow\n",
      "     |      FlowDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 4-tuple with ``(img1, img2, flow, valid_flow_mask)``\n",
      "     |          where ``valid_flow_mask`` is a numpy boolean mask of shape (H, W)\n",
      "     |          indicating which flow values are valid. The flow is a numpy array of\n",
      "     |          shape (2, H, W) and the images are PIL images. ``flow`` and ``valid_flow_mask`` are None if\n",
      "     |          ``split=\"test\"``.\n",
      "     |  \n",
      "     |  __init__(self, root, split='train', transforms=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __rmul__(self, v)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class LFWPairs(_LFW)\n",
      "     |  LFWPairs(root: str, split: str = '10fold', image_set: str = 'funneled', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
      "     |  \n",
      "     |  `LFW <http://vis-www.cs.umass.edu/lfw/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``lfw-py`` exists or will be saved to if download is set to True.\n",
      "     |      split (string, optional): The image split to use. Can be one of ``train``, ``test``,\n",
      "     |          ``10fold``. Defaults to ``10fold``.\n",
      "     |      image_set (str, optional): Type of image funneling to use, ``original``, ``funneled`` or\n",
      "     |          ``deepfunneled``. Defaults to ``funneled``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomRotation``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LFWPairs\n",
      "     |      _LFW\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any, int]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image1, image2, target) where target is `0` for different indentities and `1` for same identities.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = '10fold', image_set: str = 'funneled', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _LFW:\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  download(self)\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _LFW:\n",
      "     |  \n",
      "     |  annot_file = {'10fold': '', 'test': 'DevTest', 'train': 'DevTrain'}\n",
      "     |  \n",
      "     |  base_folder = 'lfw-py'\n",
      "     |  \n",
      "     |  checksums = {'lfw-names.txt': 'a6d0a479bd074669f656265a6e693f6d', 'pai...\n",
      "     |  \n",
      "     |  download_url_prefix = 'http://vis-www.cs.umass.edu/lfw/'\n",
      "     |  \n",
      "     |  file_dict = {'deepfunneled': ('lfw-deepfunneled', 'lfw-deepfunneled.tg...\n",
      "     |  \n",
      "     |  names = 'lfw-names.txt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class LFWPeople(_LFW)\n",
      "     |  LFWPeople(root: str, split: str = '10fold', image_set: str = 'funneled', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
      "     |  \n",
      "     |  `LFW <http://vis-www.cs.umass.edu/lfw/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``lfw-py`` exists or will be saved to if download is set to True.\n",
      "     |      split (string, optional): The image split to use. Can be one of ``train``, ``test``,\n",
      "     |          ``10fold`` (default).\n",
      "     |      image_set (str, optional): Type of image funneling to use, ``original``, ``funneled`` or\n",
      "     |          ``deepfunneled``. Defaults to ``funneled``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomRotation``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LFWPeople\n",
      "     |      _LFW\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: Tuple (image, target) where target is the identity of the person.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = '10fold', image_set: str = 'funneled', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _LFW:\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  download(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from _LFW:\n",
      "     |  \n",
      "     |  annot_file = {'10fold': '', 'test': 'DevTest', 'train': 'DevTrain'}\n",
      "     |  \n",
      "     |  base_folder = 'lfw-py'\n",
      "     |  \n",
      "     |  checksums = {'lfw-names.txt': 'a6d0a479bd074669f656265a6e693f6d', 'pai...\n",
      "     |  \n",
      "     |  download_url_prefix = 'http://vis-www.cs.umass.edu/lfw/'\n",
      "     |  \n",
      "     |  file_dict = {'deepfunneled': ('lfw-deepfunneled', 'lfw-deepfunneled.tg...\n",
      "     |  \n",
      "     |  names = 'lfw-names.txt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class LSUN(torchvision.datasets.vision.VisionDataset)\n",
      "     |  LSUN(root: str, classes: Union[str, List[str]] = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  `LSUN <https://www.yf.io/p/lsun>`_ dataset.\n",
      "     |  \n",
      "     |  You will need to install the ``lmdb`` package to use this dataset: run\n",
      "     |  ``pip install lmdb``\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory for the database files.\n",
      "     |      classes (string or list): One of {'train', 'val', 'test'} or a list of\n",
      "     |          categories to load. e,g. ['bedroom_train', 'church_outdoor_train'].\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LSUN\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: Tuple (image, target) where target is the index of the target category.\n",
      "     |  \n",
      "     |  __init__(self, root: str, classes: Union[str, List[str]] = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class LSUNClass(torchvision.datasets.vision.VisionDataset)\n",
      "     |  LSUNClass(root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LSUNClass\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class MNIST(torchvision.datasets.vision.VisionDataset)\n",
      "     |  MNIST(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where ``MNIST/raw/train-images-idx3-ubyte``\n",
      "     |          and  ``MNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
      "     |      train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
      "     |          otherwise from ``t10k-images-idx3-ubyte``.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the MNIST data if it doesn't exist already.\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', ...\n",
      "     |  \n",
      "     |  mirrors = ['http://yann.lecun.com/exdb/mnist/', 'https://ossci-dataset...\n",
      "     |  \n",
      "     |  resources = [('train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbd...\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Middlebury2014Stereo(StereoMatchingDataset)\n",
      "     |  Middlebury2014Stereo(root: str, split: str = 'train', calibration: Optional[str] = 'perfect', use_ambient_views: bool = False, transforms: Optional[Callable] = None, download: bool = False)\n",
      "     |  \n",
      "     |  Publicly available scenes from the Middlebury dataset `2014 version <https://vision.middlebury.edu/stereo/data/scenes2014/>`.\n",
      "     |  \n",
      "     |  The dataset mostly follows the original format, without containing the ambient subdirectories.  : ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          Middlebury2014\n",
      "     |              train\n",
      "     |                  scene1-{perfect,imperfect}\n",
      "     |                      calib.txt\n",
      "     |                      im{0,1}.png\n",
      "     |                      im1E.png\n",
      "     |                      im1L.png\n",
      "     |                      disp{0,1}.pfm\n",
      "     |                      disp{0,1}-n.png\n",
      "     |                      disp{0,1}-sd.pfm\n",
      "     |                      disp{0,1}y.pfm\n",
      "     |                  scene2-{perfect,imperfect}\n",
      "     |                      calib.txt\n",
      "     |                      im{0,1}.png\n",
      "     |                      im1E.png\n",
      "     |                      im1L.png\n",
      "     |                      disp{0,1}.pfm\n",
      "     |                      disp{0,1}-n.png\n",
      "     |                      disp{0,1}-sd.pfm\n",
      "     |                      disp{0,1}y.pfm\n",
      "     |                  ...\n",
      "     |              additional\n",
      "     |                  scene1-{perfect,imperfect}\n",
      "     |                      calib.txt\n",
      "     |                      im{0,1}.png\n",
      "     |                      im1E.png\n",
      "     |                      im1L.png\n",
      "     |                      disp{0,1}.pfm\n",
      "     |                      disp{0,1}-n.png\n",
      "     |                      disp{0,1}-sd.pfm\n",
      "     |                      disp{0,1}y.pfm\n",
      "     |                  ...\n",
      "     |              test\n",
      "     |                  scene1\n",
      "     |                      calib.txt\n",
      "     |                      im{0,1}.png\n",
      "     |                  scene2\n",
      "     |                      calib.txt\n",
      "     |                      im{0,1}.png\n",
      "     |                  ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the Middleburry 2014 Dataset.\n",
      "     |      split (string, optional): The dataset split of scenes, either \"train\" (default), \"test\", or \"additional\"\n",
      "     |      use_ambient_views (boolean, optional): Whether to use different expose or lightning views when possible.\n",
      "     |          The dataset samples with equal probability between ``[im1.png, im1E.png, im1L.png]``.\n",
      "     |      calibration (string, optional): Wether or not to use the calibrated (default) or uncalibrated scenes.\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |      download (boolean, optional): Wether or not to download the dataset in the ``root`` directory.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Middlebury2014Stereo\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 4-tuple with ``(img_left, img_right, disparity, valid_mask)``.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images.\n",
      "     |          ``valid_mask`` is implicitly ``None`` for `split=test`.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', calibration: Optional[str] = 'perfect', use_ambient_views: bool = False, transforms: Optional[Callable] = None, download: bool = False)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  splits = {'additional': ['Backpack', 'Bicycle1', 'Cable', 'Classroom1'...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Omniglot(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Omniglot(root: str, background: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Omniglot <https://github.com/brendenlake/omniglot>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``omniglot-py`` exists.\n",
      "     |      background (bool, optional): If True, creates dataset from the \"background\" set, otherwise\n",
      "     |          creates from the \"evaluation\" set. This terminology is defined by the authors.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset zip files from the internet and\n",
      "     |          puts it in root directory. If the zip files are already downloaded, they are not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Omniglot\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target character class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, background: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  download_url_prefix = 'https://raw.githubusercontent.com/brendenlake/o...\n",
      "     |  \n",
      "     |  folder = 'omniglot-py'\n",
      "     |  \n",
      "     |  zips_md5 = {'images_background': '68d2efa1b9178cc56df9314c21c6e718', '...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class OxfordIIITPet(torchvision.datasets.vision.VisionDataset)\n",
      "     |  OxfordIIITPet(root: str, split: str = 'trainval', target_types: Union[Sequence[str], str] = 'category', transforms: Optional[Callable] = None, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
      "     |  \n",
      "     |  `Oxford-IIIT Pet Dataset   <https://www.robots.ox.ac.uk/~vgg/data/pets/>`_.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``\"trainval\"`` (default) or ``\"test\"``.\n",
      "     |      target_types (string, sequence of strings, optional): Types of target to use. Can be ``category`` (default) or\n",
      "     |          ``segmentation``. Can also be a list to output a tuple with all specified target types. The types represent:\n",
      "     |  \n",
      "     |              - ``category`` (int): Label for one of the 37 pet categories.\n",
      "     |              - ``segmentation`` (PIL image): Segmentation trimap of the image.\n",
      "     |  \n",
      "     |          If empty, ``None`` will be returned as target.\n",
      "     |  \n",
      "     |      transform (callable, optional): A function/transform that  takes in a PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``.\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and puts it into\n",
      "     |          ``root/oxford-iiit-pet``. If dataset is already downloaded, it is not downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OxfordIIITPet\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'trainval', target_types: Union[Sequence[str], str] = 'category', transforms: Optional[Callable] = None, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class PCAM(torchvision.datasets.vision.VisionDataset)\n",
      "     |  PCAM(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
      "     |  \n",
      "     |  `PCAM Dataset   <https://github.com/basveeling/pcam>`_.\n",
      "     |  \n",
      "     |  The PatchCamelyon dataset is a binary classification dataset with 327,680\n",
      "     |  color images (96px x 96px), extracted from histopathologic scans of lymph node\n",
      "     |  sections. Each image is annotated with a binary label indicating presence of\n",
      "     |  metastatic tissue.\n",
      "     |  \n",
      "     |  This dataset requires the ``h5py`` package which you can install with ``pip install h5py``.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |       root (string): Root directory of the dataset.\n",
      "     |       split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"test\"`` or ``\"val\"``.\n",
      "     |       transform (callable, optional): A function/transform that  takes in a PIL image and returns a transformed\n",
      "     |           version. E.g, ``transforms.RandomCrop``.\n",
      "     |       target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |       download (bool, optional): If True, downloads the dataset from the internet and puts it into ``root/pcam``. If\n",
      "     |           dataset is already downloaded, it is not downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PCAM\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class PhotoTour(torchvision.datasets.vision.VisionDataset)\n",
      "     |  PhotoTour(root: str, name: str, train: bool = True, transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Multi-view Stereo Correspondence <http://matthewalunbrown.com/patchdata/patchdata.html>`_ Dataset.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      We only provide the newer version of the dataset, since the authors state that it\n",
      "     |  \n",
      "     |          is more suitable for training descriptors based on difference of Gaussian, or Harris corners, as the\n",
      "     |          patches are centred on real interest point detections, rather than being projections of 3D points as is the\n",
      "     |          case in the old dataset.\n",
      "     |  \n",
      "     |      The original dataset is available under http://phototour.cs.washington.edu/patches/default.htm.\n",
      "     |  \n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images are.\n",
      "     |      name (string): Name of the dataset to load.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PhotoTour\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Union[torch.Tensor, Tuple[Any, Any, torch.Tensor]]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (data1, data2, matches)\n",
      "     |  \n",
      "     |  __init__(self, root: str, name: str, train: bool = True, transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  cache(self) -> None\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  image_ext = 'bmp'\n",
      "     |  \n",
      "     |  info_file = 'info.txt'\n",
      "     |  \n",
      "     |  lens = {'liberty': 450092, 'liberty_harris': 379587, 'notredame': 4681...\n",
      "     |  \n",
      "     |  matches_files = 'm50_100000_100000_0.txt'\n",
      "     |  \n",
      "     |  means = {'liberty': 0.4437, 'liberty_harris': 0.4437, 'notredame': 0.4...\n",
      "     |  \n",
      "     |  stds = {'liberty': 0.2019, 'liberty_harris': 0.2019, 'notredame': 0.18...\n",
      "     |  \n",
      "     |  urls = {'liberty': ['http://icvl.ee.ic.ac.uk/vbalnt/liberty.zip', 'lib...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Places365(torchvision.datasets.vision.VisionDataset)\n",
      "     |  Places365(root: str, split: str = 'train-standard', small: bool = False, download: bool = False, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = <function default_loader at 0x00000205DAF38430>) -> None\n",
      "     |  \n",
      "     |  `Places365 <http://places2.csail.mit.edu/index.html>`_ classification dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the Places365 dataset.\n",
      "     |      split (string, optional): The dataset split. Can be one of ``train-standard`` (default), ``train-challenge``,\n",
      "     |          ``val``.\n",
      "     |      small (bool, optional): If ``True``, uses the small images, i. e. resized to 256 x 256 pixels, instead of the\n",
      "     |          high resolution ones.\n",
      "     |      download (bool, optional): If ``True``, downloads the dataset components and places them in ``root``. Already\n",
      "     |          downloaded archives are not downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      loader (callable, optional): A function to load an image given its path.\n",
      "     |  \n",
      "     |   Attributes:\n",
      "     |      classes (list): List of the class names.\n",
      "     |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "     |      imgs (list): List of (image path, class_index) tuples\n",
      "     |      targets (list): The class_index value for each image in the dataset\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |      RuntimeError: If ``download is False`` and the meta files, i. e. the devkit, are not present or corrupted.\n",
      "     |      RuntimeError: If ``download is True`` and the image archive is already extracted.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Places365\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train-standard', small: bool = False, download: bool = False, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = <function default_loader at 0x00000205DAF38430>) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download_devkit(self) -> None\n",
      "     |  \n",
      "     |  download_images(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  load_categories(self, download: bool = True) -> Tuple[List[str], Dict[str, int]]\n",
      "     |  \n",
      "     |  load_file_list(self, download: bool = True) -> Tuple[List[Tuple[str, int]], List[int]]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  images_dir\n",
      "     |  \n",
      "     |  variant\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class QMNIST(MNIST)\n",
      "     |  QMNIST(root: str, what: Optional[str] = None, compat: bool = True, train: bool = True, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  `QMNIST <https://github.com/facebookresearch/qmnist>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset whose ``raw``\n",
      "     |          subdir contains binary files of the datasets.\n",
      "     |      what (string,optional): Can be 'train', 'test', 'test10k',\n",
      "     |          'test50k', or 'nist' for respectively the mnist compatible\n",
      "     |          training set, the 60k qmnist testing set, the 10k qmnist\n",
      "     |          examples that match the mnist testing set, the 50k\n",
      "     |          remaining qmnist testing examples, or all the nist\n",
      "     |          digits. The default is to select 'train' or 'test'\n",
      "     |          according to the compatibility argument 'train'.\n",
      "     |      compat (bool,optional): A boolean that says whether the target\n",
      "     |          for each example is class number (for compatibility with\n",
      "     |          the MNIST dataloader) or a torch vector containing the\n",
      "     |          full qmnist information. Default=True.\n",
      "     |      download (bool, optional): If True, downloads the dataset from\n",
      "     |          the internet and puts it in root directory. If dataset is\n",
      "     |          already downloaded, it is not downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that\n",
      "     |          takes in an PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform\n",
      "     |          that takes in the target and transforms it.\n",
      "     |      train (bool,optional,compatibility): When argument 'what' is\n",
      "     |          not specified, this boolean decides whether to load the\n",
      "     |          training set ot the testing set.  Default: True.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QMNIST\n",
      "     |      MNIST\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, what: Optional[str] = None, compat: bool = True, train: bool = True, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download the QMNIST data if it doesn't exist already.\n",
      "     |      Note that we only download what has been asked for (argument 'what').\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  images_file\n",
      "     |  \n",
      "     |  labels_file\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'resources': typing.Dict[str, typing.List[typing.Tu...\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', ...\n",
      "     |  \n",
      "     |  resources = {'nist': [('https://raw.githubusercontent.com/facebookrese...\n",
      "     |  \n",
      "     |  subsets = {'nist': 'nist', 'test': 'test', 'test10k': 'test', 'test50k...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from MNIST:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from MNIST:\n",
      "     |  \n",
      "     |  class_to_idx\n",
      "     |  \n",
      "     |  processed_folder\n",
      "     |  \n",
      "     |  raw_folder\n",
      "     |  \n",
      "     |  test_data\n",
      "     |  \n",
      "     |  test_labels\n",
      "     |  \n",
      "     |  train_data\n",
      "     |  \n",
      "     |  train_labels\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from MNIST:\n",
      "     |  \n",
      "     |  mirrors = ['http://yann.lecun.com/exdb/mnist/', 'https://ossci-dataset...\n",
      "     |  \n",
      "     |  test_file = 'test.pt'\n",
      "     |  \n",
      "     |  training_file = 'training.pt'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class RenderedSST2(torchvision.datasets.vision.VisionDataset)\n",
      "     |  RenderedSST2(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `The Rendered SST2 Dataset <https://github.com/openai/CLIP/blob/main/data/rendered-sst2.md>`_.\n",
      "     |  \n",
      "     |  Rendered SST2 is an image classification dataset used to evaluate the models capability on optical\n",
      "     |  character recognition. This dataset was generated by rendering sentences in the Standford Sentiment\n",
      "     |  Treebank v2 dataset.\n",
      "     |  \n",
      "     |  This dataset contains two classes (positive and negative) and is divided in three splits: a  train\n",
      "     |  split containing 6920 images (3610 positive and 3310 negative), a validation split containing 872 images\n",
      "     |  (444 positive and 428 negative), and a test split containing 1821 images (909 positive and 912 negative).\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the dataset.\n",
      "     |      split (string, optional): The dataset split, supports ``\"train\"`` (default), `\"val\"` and ``\"test\"``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``.\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again. Default is False.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RenderedSST2\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class SBDataset(torchvision.datasets.vision.VisionDataset)\n",
      "     |  SBDataset(root: str, image_set: str = 'train', mode: str = 'boundaries', download: bool = False, transforms: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  `Semantic Boundaries Dataset <http://home.bharathh.info/pubs/codes/SBD/download.html>`_\n",
      "     |  \n",
      "     |  The SBD currently contains annotations from 11355 images taken from the PASCAL VOC 2011 dataset.\n",
      "     |  \n",
      "     |  .. note ::\n",
      "     |  \n",
      "     |      Please note that the train and val splits included with this dataset are different from\n",
      "     |      the splits in the PASCAL VOC dataset. In particular some \"train\" images might be part of\n",
      "     |      VOC2012 val.\n",
      "     |      If you are interested in testing on VOC 2012 val, then use `image_set='train_noval'`,\n",
      "     |      which excludes all val images.\n",
      "     |  \n",
      "     |  .. warning::\n",
      "     |  \n",
      "     |      This class needs `scipy <https://docs.scipy.org/doc/>`_ to load target files from `.mat` format.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the Semantic Boundaries Dataset\n",
      "     |      image_set (string, optional): Select the image_set to use, ``train``, ``val`` or ``train_noval``.\n",
      "     |          Image set ``train_noval`` excludes VOC 2012 val images.\n",
      "     |      mode (string, optional): Select target type. Possible values 'boundaries' or 'segmentation'.\n",
      "     |          In case of 'boundaries', the target is an array of shape `[num_classes, H, W]`,\n",
      "     |          where `num_classes=20`.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version. Input sample is PIL image and target is a numpy array\n",
      "     |          if `mode='boundaries'` or PIL image if `mode='segmentation'`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SBDataset\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, image_set: str = 'train', mode: str = 'boundaries', download: bool = False, transforms: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  filename = 'benchmark.tgz'\n",
      "     |  \n",
      "     |  md5 = '82b4d87ceb2ed10f6038a1cba92111cb'\n",
      "     |  \n",
      "     |  url = 'https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grou...\n",
      "     |  \n",
      "     |  voc_split_filename = 'train_noval.txt'\n",
      "     |  \n",
      "     |  voc_split_md5 = '79bff800c5f0b1ec6b21080a3c066722'\n",
      "     |  \n",
      "     |  voc_train_url = 'http://home.bharathh.info/pubs/codes/SBD/train_noval....\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class SBU(torchvision.datasets.vision.VisionDataset)\n",
      "     |  SBU(root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = True) -> None\n",
      "     |  \n",
      "     |  `SBU Captioned Photo <http://www.cs.virginia.edu/~vicente/sbucaptions/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where tarball\n",
      "     |          ``SBUCaptionedPhotoDataset.tar.gz`` exists.\n",
      "     |      transform (callable, optional): A function/transform that takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SBU\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is a caption for the photo.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = True) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |      The number of photos in the dataset.\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |      Download and extract the tarball, and download each individual photo.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  filename = 'SBUCaptionedPhotoDataset.tar.gz'\n",
      "     |  \n",
      "     |  md5_checksum = '9aec147b3488753cf758b4d493422285'\n",
      "     |  \n",
      "     |  url = 'https://www.cs.rice.edu/~vo9/sbucaptions/SBUCaptionedPhotoDatas...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class SEMEION(torchvision.datasets.vision.VisionDataset)\n",
      "     |  SEMEION(root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = True) -> None\n",
      "     |  \n",
      "     |  `SEMEION <http://archive.ics.uci.edu/ml/datasets/semeion+handwritten+digit>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``semeion.py`` exists.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SEMEION\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = True) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  filename = 'semeion.data'\n",
      "     |  \n",
      "     |  md5_checksum = 'cb545d371d2ce14ec121470795a77432'\n",
      "     |  \n",
      "     |  url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/semeio...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class STL10(torchvision.datasets.vision.VisionDataset)\n",
      "     |  STL10(root: str, split: str = 'train', folds: Optional[int] = None, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `STL10 <https://cs.stanford.edu/~acoates/stl10/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset where directory\n",
      "     |          ``stl10_binary`` exists.\n",
      "     |      split (string): One of {'train', 'test', 'unlabeled', 'train+unlabeled'}.\n",
      "     |          Accordingly dataset is selected.\n",
      "     |      folds (int, optional): One of {0-9} or None.\n",
      "     |          For training, loads one of the 10 pre-defined folds of 1k samples for the\n",
      "     |          standard evaluation procedure. If no value is passed, loads the 5k samples.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      STL10\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', folds: Optional[int] = None, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  base_folder = 'stl10_binary'\n",
      "     |  \n",
      "     |  class_names_file = 'class_names.txt'\n",
      "     |  \n",
      "     |  filename = 'stl10_binary.tar.gz'\n",
      "     |  \n",
      "     |  folds_list_file = 'fold_indices.txt'\n",
      "     |  \n",
      "     |  splits = ('train', 'train+unlabeled', 'unlabeled', 'test')\n",
      "     |  \n",
      "     |  test_list = [['test_X.bin', '7f263ba9f9e0b06b93213547f721ac82'], ['tes...\n",
      "     |  \n",
      "     |  tgz_md5 = '91f7769df0f17e558f3565bffb0c7dfb'\n",
      "     |  \n",
      "     |  train_list = [['train_X.bin', '918c2871b30a85fa023e0c44e0bee87f'], ['t...\n",
      "     |  \n",
      "     |  url = 'http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class SUN397(torchvision.datasets.vision.VisionDataset)\n",
      "     |  SUN397(root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `The SUN397 Data Set <https://vision.princeton.edu/projects/2010/SUN/>`_.\n",
      "     |  \n",
      "     |  The SUN397 or Scene UNderstanding (SUN) is a dataset for scene recognition consisting of\n",
      "     |  397 categories with 108'754 images.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the dataset.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image and returns a transformed\n",
      "     |          version. E.g, ``transforms.RandomCrop``.\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SUN397\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class SVHN(torchvision.datasets.vision.VisionDataset)\n",
      "     |  SVHN(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `SVHN <http://ufldl.stanford.edu/housenumbers/>`_ Dataset.\n",
      "     |  Note: The SVHN dataset assigns the label `10` to the digit `0`. However, in this Dataset,\n",
      "     |  we assign the label `0` to the digit `0` to be compatible with PyTorch loss functions which\n",
      "     |  expect the class labels to be in the range `[0, C-1]`\n",
      "     |  \n",
      "     |  .. warning::\n",
      "     |  \n",
      "     |      This class needs `scipy <https://docs.scipy.org/doc/>`_ to load data from `.mat` format.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the dataset where the data is stored.\n",
      "     |      split (string): One of {'train', 'test', 'extra'}.\n",
      "     |          Accordingly dataset is selected. 'extra' is Extra training set.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SVHN\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  split_list = {'extra': ['http://ufldl.stanford.edu/housenumbers/extra_...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class SceneFlowStereo(StereoMatchingDataset)\n",
      "     |  SceneFlowStereo(root: str, variant: str = 'FlyingThings3D', pass_name: str = 'clean', transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  Dataset interface for `Scene Flow <https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html>`_ datasets.\n",
      "     |  This interface provides access to the `FlyingThings3D, `Monkaa` and `Driving` datasets.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structre: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          SceneFlow\n",
      "     |              Monkaa\n",
      "     |                  frames_cleanpass\n",
      "     |                      scene1\n",
      "     |                          left\n",
      "     |                              img1.png\n",
      "     |                              img2.png\n",
      "     |                          right\n",
      "     |                              img1.png\n",
      "     |                              img2.png\n",
      "     |                      scene2\n",
      "     |                          left\n",
      "     |                              img1.png\n",
      "     |                              img2.png\n",
      "     |                          right\n",
      "     |                              img1.png\n",
      "     |                              img2.png\n",
      "     |                  frames_finalpass\n",
      "     |                      scene1\n",
      "     |                          left\n",
      "     |                              img1.png\n",
      "     |                              img2.png\n",
      "     |                          right\n",
      "     |                              img1.png\n",
      "     |                              img2.png\n",
      "     |                      ...\n",
      "     |                      ...\n",
      "     |                  disparity\n",
      "     |                      scene1\n",
      "     |                          left\n",
      "     |                              img1.pfm\n",
      "     |                              img2.pfm\n",
      "     |                          right\n",
      "     |                              img1.pfm\n",
      "     |                              img2.pfm\n",
      "     |              FlyingThings3D\n",
      "     |                  ...\n",
      "     |                  ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where SceneFlow is located.\n",
      "     |      variant (string): Which dataset variant to user, \"FlyingThings3D\" (default), \"Monkaa\" or \"Driving\".\n",
      "     |      pass_name (string): Which pass to use, \"clean\" (default), \"final\" or \"both\".\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SceneFlowStereo\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 3-tuple with ``(img_left, img_right, disparity)``.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images.\n",
      "     |          If a ``valid_mask`` is generated within the ``transforms`` parameter,\n",
      "     |          a 4-tuple with ``(img_left, img_right, disparity, valid_mask)`` is returned.\n",
      "     |  \n",
      "     |  __init__(self, root: str, variant: str = 'FlyingThings3D', pass_name: str = 'clean', transforms: Optional[Callable] = None)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class Sintel(FlowDataset)\n",
      "     |  Sintel(root, split='train', pass_name='clean', transforms=None)\n",
      "     |  \n",
      "     |  `Sintel <http://sintel.is.tue.mpg.de/>`_ Dataset for optical flow.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          Sintel\n",
      "     |              testing\n",
      "     |                  clean\n",
      "     |                      scene_1\n",
      "     |                      scene_2\n",
      "     |                      ...\n",
      "     |                  final\n",
      "     |                      scene_1\n",
      "     |                      scene_2\n",
      "     |                      ...\n",
      "     |              training\n",
      "     |                  clean\n",
      "     |                      scene_1\n",
      "     |                      scene_2\n",
      "     |                      ...\n",
      "     |                  final\n",
      "     |                      scene_1\n",
      "     |                      scene_2\n",
      "     |                      ...\n",
      "     |                  flow\n",
      "     |                      scene_1\n",
      "     |                      scene_2\n",
      "     |                      ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the Sintel Dataset.\n",
      "     |      split (string, optional): The dataset split, either \"train\" (default) or \"test\"\n",
      "     |      pass_name (string, optional): The pass to use, either \"clean\" (default), \"final\", or \"both\". See link above for\n",
      "     |          details on the different passes.\n",
      "     |      transforms (callable, optional): A function/transform that takes in\n",
      "     |          ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n",
      "     |          ``valid_flow_mask`` is expected for consistency with other datasets which\n",
      "     |          return a built-in valid mask, such as :class:`~torchvision.datasets.KittiFlow`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Sintel\n",
      "     |      FlowDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 3-tuple with ``(img1, img2, flow)``.\n",
      "     |          The flow is a numpy array of shape (2, H, W) and the images are PIL images.\n",
      "     |          ``flow`` is None if ``split=\"test\"``.\n",
      "     |          If a valid flow mask is generated within the ``transforms`` parameter,\n",
      "     |          a 4-tuple with ``(img1, img2, flow, valid_flow_mask)`` is returned.\n",
      "     |  \n",
      "     |  __init__(self, root, split='train', pass_name='clean', transforms=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __rmul__(self, v)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FlowDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class SintelStereo(StereoMatchingDataset)\n",
      "     |  SintelStereo(root: str, pass_name: str = 'final', transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  Sintel `Stereo Dataset <http://sintel.is.tue.mpg.de/stereo>`_.\n",
      "     |  \n",
      "     |  The dataset is expected to have the following structure: ::\n",
      "     |  \n",
      "     |      root\n",
      "     |          Sintel\n",
      "     |              training\n",
      "     |                  final_left\n",
      "     |                      scene1\n",
      "     |                          img1.png\n",
      "     |                          img2.png\n",
      "     |                          ...\n",
      "     |                      ...\n",
      "     |                  final_right\n",
      "     |                      scene2\n",
      "     |                          img1.png\n",
      "     |                          img2.png\n",
      "     |                          ...\n",
      "     |                      ...\n",
      "     |                  disparities\n",
      "     |                      scene1\n",
      "     |                          img1.png\n",
      "     |                          img2.png\n",
      "     |                          ...\n",
      "     |                      ...\n",
      "     |                  occlusions\n",
      "     |                      scene1\n",
      "     |                          img1.png\n",
      "     |                          img2.png\n",
      "     |                          ...\n",
      "     |                      ...\n",
      "     |                  outofframe\n",
      "     |                      scene1\n",
      "     |                          img1.png\n",
      "     |                          img2.png\n",
      "     |                          ...\n",
      "     |                      ...\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where Sintel Stereo is located.\n",
      "     |      pass_name (string): The name of the pass to use, either \"final\", \"clean\" or \"both\".\n",
      "     |      transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SintelStereo\n",
      "     |      StereoMatchingDataset\n",
      "     |      abc.ABC\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple\n",
      "     |      Return example at given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index(int): The index of the example to retrieve\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: A 4-tuple with ``(img_left, img_right, disparity, valid_mask)`` is returned.\n",
      "     |          The disparity is a numpy array of shape (1, H, W) and the images are PIL images whilst\n",
      "     |          the valid_mask is a numpy array of shape (H, W).\n",
      "     |  \n",
      "     |  __init__(self, root: str, pass_name: str = 'final', transforms: Optional[Callable] = None)\n",
      "     |      Args:\n",
      "     |          root(str): Root directory of the dataset.\n",
      "     |          transforms(callable, optional): A function/transform that takes in Tuples of\n",
      "     |              (images, disparities, valid_masks) and returns a transformed version of each of them.\n",
      "     |              images is a Tuple of (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (1, H, W)\n",
      "     |              valid_masks is a Tuple of (``np.ndarray``, ``np.ndarray``) with shape (H, W)\n",
      "     |              In some cases, when a dataset does not provide disparities, the ``disparities`` and\n",
      "     |              ``valid_masks`` can be Tuples containing None values.\n",
      "     |              For training splits generally the datasets provide a minimal guarantee of\n",
      "     |              images: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``np.ndarray``, ``None``) with shape (1, H, W)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``np.ndarray | None``, ``None``) with shape (H, W)\n",
      "     |              For some test splits, the datasets provides outputs that look like:\n",
      "     |              imgaes: (``PIL.Image``, ``PIL.Image``)\n",
      "     |              disparities: (``None``, ``None``)\n",
      "     |              Optionally, based on the dataset, it can return a ``mask`` as well:\n",
      "     |              valid_masks: (``None``, ``None``)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from StereoMatchingDataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from abc.ABCMeta\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from abc.ABCMeta\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class StanfordCars(torchvision.datasets.vision.VisionDataset)\n",
      "     |  StanfordCars(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `Stanford Cars <https://ai.stanford.edu/~jkrause/cars/car_dataset.html>`_ Dataset\n",
      "     |  \n",
      "     |  The Cars dataset contains 16,185 images of 196 classes of cars. The data is\n",
      "     |  split into 8,144 training images and 8,041 testing images, where each class\n",
      "     |  has been split roughly in a 50-50 split\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      This class needs `scipy <https://docs.scipy.org/doc/>`_ to load target files from `.mat` format.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset\n",
      "     |      split (string, optional): The dataset split, supports ``\"train\"`` (default) or ``\"test\"``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If True, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StanfordCars\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx: int) -> Tuple[Any, Any]\n",
      "     |      Returns pil_image and class_id for given index\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class UCF101(torchvision.datasets.vision.VisionDataset)\n",
      "     |  UCF101(root: str, annotation_path: str, frames_per_clip: int, step_between_clips: int = 1, frame_rate: Optional[int] = None, fold: int = 1, train: bool = True, transform: Optional[Callable] = None, _precomputed_metadata: Optional[Dict[str, Any]] = None, num_workers: int = 1, _video_width: int = 0, _video_height: int = 0, _video_min_dimension: int = 0, _audio_samples: int = 0, output_format: str = 'THWC') -> None\n",
      "     |  \n",
      "     |  `UCF101 <https://www.crcv.ucf.edu/data/UCF101.php>`_ dataset.\n",
      "     |  \n",
      "     |  UCF101 is an action recognition video dataset.\n",
      "     |  This dataset consider every video as a collection of video clips of fixed size, specified\n",
      "     |  by ``frames_per_clip``, where the step in frames between each clip is given by\n",
      "     |  ``step_between_clips``. The dataset itself can be downloaded from the dataset website;\n",
      "     |  annotations that ``annotation_path`` should be pointing to can be downloaded from `here\n",
      "     |  <https://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip>`_.\n",
      "     |  \n",
      "     |  To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``\n",
      "     |  and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two\n",
      "     |  elements will come from video 1, and the next three elements from video 2.\n",
      "     |  Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all\n",
      "     |  frames in a video might be present.\n",
      "     |  \n",
      "     |  Internally, it uses a VideoClips object to handle clip creation.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the UCF101 Dataset.\n",
      "     |      annotation_path (str): path to the folder containing the split files;\n",
      "     |          see docstring above for download instructions of these files\n",
      "     |      frames_per_clip (int): number of frames in a clip.\n",
      "     |      step_between_clips (int, optional): number of frames between each clip.\n",
      "     |      fold (int, optional): which fold to use. Should be between 1 and 3.\n",
      "     |      train (bool, optional): if ``True``, creates a dataset from the train split,\n",
      "     |          otherwise from the ``test`` split.\n",
      "     |      transform (callable, optional): A function/transform that  takes in a TxHxWxC video\n",
      "     |          and returns a transformed version.\n",
      "     |      output_format (str, optional): The format of the output video tensors (before transforms).\n",
      "     |          Can be either \"THWC\" (default) or \"TCHW\".\n",
      "     |  \n",
      "     |  Returns:\n",
      "     |      tuple: A 3-tuple with the following entries:\n",
      "     |  \n",
      "     |          - video (Tensor[T, H, W, C] or Tensor[T, C, H, W]): The `T` video frames\n",
      "     |          -  audio(Tensor[K, L]): the audio frames, where `K` is the number of channels\n",
      "     |             and `L` is the number of points\n",
      "     |          - label (int): class of the video clip\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UCF101\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, annotation_path: str, frames_per_clip: int, step_between_clips: int = 1, frame_rate: Optional[int] = None, fold: int = 1, train: bool = True, transform: Optional[Callable] = None, _precomputed_metadata: Optional[Dict[str, Any]] = None, num_workers: int = 1, _video_width: int = 0, _video_height: int = 0, _video_min_dimension: int = 0, _audio_samples: int = 0, output_format: str = 'THWC') -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  metadata\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class USPS(torchvision.datasets.vision.VisionDataset)\n",
      "     |  USPS(root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `USPS <https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#usps>`_ Dataset.\n",
      "     |  The data-format is : [label [index:value ]*256 \\n] * num_lines, where ``label`` lies in ``[1, 10]``.\n",
      "     |  The value for each pixel lies in ``[-1, 1]``. Here we transform the ``label`` into ``[0, 9]``\n",
      "     |  and make pixel values in ``[0, 255]``.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset to store``USPS`` data files.\n",
      "     |      train (bool, optional): If True, creates dataset from ``usps.bz2``,\n",
      "     |          otherwise from ``usps.t.bz2``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      USPS\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is index of the target class.\n",
      "     |  \n",
      "     |  __init__(self, root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  split_list = {'test': ['https://www.csie.ntu.edu.tw/~cjlin/libsvmtools...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class VOCDetection(_VOCBase)\n",
      "     |  VOCDetection(root: str, year: str = '2012', image_set: str = 'train', download: bool = False, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  `Pascal VOC <http://host.robots.ox.ac.uk/pascal/VOC/>`_ Detection Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the VOC Dataset.\n",
      "     |      year (string, optional): The dataset year, supports years ``\"2007\"`` to ``\"2012\"``.\n",
      "     |      image_set (string, optional): Select the image_set to use, ``\"train\"``, ``\"trainval\"`` or ``\"val\"``. If\n",
      "     |          ``year==\"2007\"``, can also be ``\"test\"``.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |          (default: alphabetic indexing of VOC's 20 classes).\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, required): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VOCDetection\n",
      "     |      _VOCBase\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is a dictionary of the XML tree.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  parse_voc_xml(node: xml.etree.ElementTree.Element) -> Dict[str, Any]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  annotations\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _VOCBase:\n",
      "     |  \n",
      "     |  __init__(self, root: str, year: str = '2012', image_set: str = 'train', download: bool = False, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class VOCSegmentation(_VOCBase)\n",
      "     |  VOCSegmentation(root: str, year: str = '2012', image_set: str = 'train', download: bool = False, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None)\n",
      "     |  \n",
      "     |  `Pascal VOC <http://host.robots.ox.ac.uk/pascal/VOC/>`_ Segmentation Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of the VOC Dataset.\n",
      "     |      year (string, optional): The dataset year, supports years ``\"2007\"`` to ``\"2012\"``.\n",
      "     |      image_set (string, optional): Select the image_set to use, ``\"train\"``, ``\"trainval\"`` or ``\"val\"``. If\n",
      "     |          ``year==\"2007\"``, can also be ``\"test\"``.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
      "     |          and returns a transformed version.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VOCSegmentation\n",
      "     |      _VOCBase\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is the image segmentation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  masks\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _VOCBase:\n",
      "     |  \n",
      "     |  __init__(self, root: str, year: str = '2012', image_set: str = 'train', download: bool = False, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class VisionDataset(torch.utils.data.dataset.Dataset)\n",
      "     |  VisionDataset(root: str, transforms: Optional[Callable] = None, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |  \n",
      "     |  Base Class For making datasets which are compatible with torchvision.\n",
      "     |  It is necessary to override the ``__getitem__`` and ``__len__`` method.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory of dataset.\n",
      "     |      transforms (callable, optional): A function/transforms that takes in\n",
      "     |          an image and a label and returns the transformed versions of both.\n",
      "     |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      :attr:`transforms` and the combination of :attr:`transform` and :attr:`target_transform` are mutually exclusive.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Any\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          (Any): Sample and meta data, optionally transformed by the respective transforms.\n",
      "     |  \n",
      "     |  __init__(self, root: str, transforms: Optional[Callable] = None, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "    \n",
      "    class WIDERFace(torchvision.datasets.vision.VisionDataset)\n",
      "     |  WIDERFace(root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |  \n",
      "     |  `WIDERFace <http://shuoyang1213.me/WIDERFACE/>`_ Dataset.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      root (string): Root directory where images and annotations are downloaded to.\n",
      "     |          Expects the following folder structure if download=False:\n",
      "     |  \n",
      "     |          .. code::\n",
      "     |  \n",
      "     |              <root>\n",
      "     |                  └── widerface\n",
      "     |                      ├── wider_face_split ('wider_face_split.zip' if compressed)\n",
      "     |                      ├── WIDER_train ('WIDER_train.zip' if compressed)\n",
      "     |                      ├── WIDER_val ('WIDER_val.zip' if compressed)\n",
      "     |                      └── WIDER_test ('WIDER_test.zip' if compressed)\n",
      "     |      split (string): The dataset split to use. One of {``train``, ``val``, ``test``}.\n",
      "     |          Defaults to ``train``.\n",
      "     |      transform (callable, optional): A function/transform that  takes in a PIL image\n",
      "     |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "     |      target_transform (callable, optional): A function/transform that takes in the\n",
      "     |          target and transforms it.\n",
      "     |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      "     |          puts it in root directory. If dataset is already downloaded, it is not\n",
      "     |          downloaded again.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WIDERFace\n",
      "     |      torchvision.datasets.vision.VisionDataset\n",
      "     |      torch.utils.data.dataset.Dataset\n",
      "     |      typing.Generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      "     |      Args:\n",
      "     |          index (int): Index\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          tuple: (image, target) where target is a dict of annotations for all faces in the image.\n",
      "     |          target=None for the test split.\n",
      "     |  \n",
      "     |  __init__(self, root: str, split: str = 'train', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |  \n",
      "     |  download(self) -> None\n",
      "     |  \n",
      "     |  extra_repr(self) -> str\n",
      "     |  \n",
      "     |  parse_test_annotations_file(self) -> None\n",
      "     |  \n",
      "     |  parse_train_val_annotations_file(self) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ANNOTATIONS_FILE = ('http://shuoyang1213.me/WIDERFACE/support/bbx_anno...\n",
      "     |  \n",
      "     |  BASE_FOLDER = 'widerface'\n",
      "     |  \n",
      "     |  FILE_LIST = [('15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M', '3fedf70df600953d25...\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  __parameters__ = ()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      "     |  \n",
      "     |  __repr__(self) -> str\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from typing.Generic:\n",
      "     |  \n",
      "     |  __class_getitem__(params) from builtins.type\n",
      "     |  \n",
      "     |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |      \n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "\n",
      "DATA\n",
      "    __all__ = ('LSUN', 'LSUNClass', 'ImageFolder', 'DatasetFolder', 'FakeD...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\ksk\\anaconda3\\envs\\pytlesson\\lib\\site-packages\\torchvision\\datasets\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torchvision.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f121b89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for img,label in (train_loader) : \n",
    "    img = img.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std* img + mean\n",
    "    img = np.clip(img,0,1)\n",
    "    plt.imshow(img)\n",
    "    break\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "## 위에서 이미지를 텐서화 하고 일반화 했기 때문에 원래 상태(BGR)로 되돌려야 이미지를 볼 수 있음.\n",
    "    \n",
    "for i in range(10) : \n",
    "    ax = fig.add_subplot(2,5,i+1,xticks=[],yticks=[])\n",
    "    ## 2행 5열의 이미지 테이블 준비, 이미지를 출력할 원소 위치\n",
    "    ax.set_title(i)\n",
    "    img = next(img for img,label in train_loader if label==i)\n",
    "    img = img.numpy().transpose(1,2,0)\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std* img + mean\n",
    "    img = np.clip(img,0,1)\n",
    "    plt.imshow(img)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "## 이미지 테이블의 세로 간격을 조절할 수 있음.\n",
    "plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bba23c77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32]) tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
      "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
      "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
      "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
      "        6, 0, 0, 7, 4, 5, 6, 3, 1, 1, 3, 6, 8, 7, 4, 0, 6, 2, 1, 3, 0, 4, 2, 7,\n",
      "        8, 3, 1, 2, 8, 0, 8, 3])\n",
      "391\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_loader1 = torch.utils.data.DataLoader(train_loader,batch_size=batch_size,shuffle=True)\n",
    "test_loader1 = torch.utils.data.DataLoader(test_loader,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "for a,b in test_loader1 : \n",
    "    print(a.shape,b)\n",
    "    break\n",
    "print(len(train_loader1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7934f",
   "metadata": {},
   "source": [
    "### 옵티마이저와 손실함수 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58432e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a552c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch.optim in torch:\n",
      "\n",
      "NAME\n",
      "    torch.optim\n",
      "\n",
      "DESCRIPTION\n",
      "    :mod:`torch.optim` is a package implementing various optimization algorithms.\n",
      "    Most commonly used methods are already supported, and the interface is general\n",
      "    enough, so that more sophisticated ones can be also easily integrated in the\n",
      "    future.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _functional\n",
      "    _multi_tensor (package)\n",
      "    adadelta\n",
      "    adagrad\n",
      "    adam\n",
      "    adamax\n",
      "    adamw\n",
      "    asgd\n",
      "    lbfgs\n",
      "    lr_scheduler\n",
      "    nadam\n",
      "    optimizer\n",
      "    radam\n",
      "    rmsprop\n",
      "    rprop\n",
      "    sgd\n",
      "    sparse_adam\n",
      "    swa_utils\n",
      "\n",
      "FILE\n",
      "    c:\\users\\ksk\\anaconda3\\envs\\pytlesson\\lib\\site-packages\\torch\\optim\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f77ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model,data_loader,device=\"cuda:0\") : \n",
    "    model.eval()\n",
    "    ys = []\n",
    "    ypreds=[]\n",
    "    for x,y in data_loader : \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            _,y_pred = model(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "        \n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    acc = (ys==ypreds).float().sum()/len(ys)\n",
    "    return acc.item()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ecaf2f",
   "metadata": {},
   "source": [
    "### 훈련 코드 짜기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73b0ce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [01:04<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.631671568751335 0.66744 0.7069999575614929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [01:04<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4.121691561490297 0.70648 0.7251999974250793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [01:04<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3.7673104628920555 0.72918 0.7427999973297119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 391/391 [01:04<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3.443892255425453 0.75184 0.7400999665260315\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "net.to(device)\n",
    "EPOCHS=4\n",
    "log_train_loss=[]\n",
    "log_train_acc=[]\n",
    "log_valid_acc=[]\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0.0\n",
    "    n=0\n",
    "    acc=0\n",
    "    i = 0\n",
    "    net.train()\n",
    "    for I,(img,label) in tqdm.tqdm(enumerate(train_loader1),total = len(train_loader1)) :\n",
    "        ## 50000만장의 훈련 데이터를 128 미니배치로 학습하므로 한 에포크 당 for문은 총 391번 돌게된다.\n",
    "        img=img.to(device)\n",
    "        label=label.to(device)\n",
    "        h=net(img)\n",
    "        loss=loss_fn(h,label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss+=loss.item()\n",
    "        n += len(img)\n",
    "        _,y_pred = h.max(1)\n",
    "        acc += (label==y_pred).sum().item()\n",
    "    log_train_loss.append(epoch_loss/len(img))\n",
    "    ## 한 에포크당 손실\n",
    "    log_train_acc.append(acc/n)\n",
    "    ## 한 에포크당 정확성 n=128*391\n",
    "    log_valid_acc.append(eval_model(net,test_loader1,device))\n",
    "    ## 한 에포크당 테스트용 데이터의 정확성\n",
    "    print(epoch,log_train_loss[-1],log_train_acc[-1],log_valid_acc[-1],flush=True)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0ecd4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(4),log_train_acc,'o--',markevery=10)\n",
    "plt.title(\"Train_acc\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(4),log_valid_acc,'o--',markevery=10)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.grid()\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "## 각 그래프의 가로 간격을 조정하는 메서드\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
